<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="jepusto/SCD-Methods-Guide" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  



<meta name="date" content="2023-12-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="illustrate-D-CES.html"/>
<link rel="next" href="illustrate-D-CES-Btrends.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Synthesis of Single-Case Designs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Authors</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#citation"><i class="fa fa-check"></i>Citation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#datasets"><i class="fa fa-check"></i>Datasets</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Approaches for Estimation and Synthesis of Single-Case Studies</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#purpose-of-the-methods-guide"><i class="fa fa-check"></i><b>1.2</b> Purpose of the Methods Guide</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#study-quality"><i class="fa fa-check"></i><b>1.3</b> Study Quality</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#selecting-an-approach-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.4</b> Selecting an Approach for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#design-comparable-effect-sizes"><i class="fa fa-check"></i><b>1.5</b> Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#case-specific-effect-sizes"><i class="fa fa-check"></i><b>1.6</b> Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#multilevel-modeling-of-individual-participant-interrupted-time-series-data"><i class="fa fa-check"></i><b>1.7</b> Multilevel Modeling of Individual Participant Interrupted Time-Series Data</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#summary-of-options-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.8</b> Summary of Options for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#limitations-in-selecting-an-approach-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.9</b> Limitations in Selecting an Approach for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#structure-of-the-methods-guide"><i class="fa fa-check"></i><b>1.10</b> Structure of the Methods Guide</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="D-CES.html"><a href="D-CES.html"><i class="fa fa-check"></i><b>2</b> Introduction to Design-Comparable Effect Sizes</a>
<ul>
<li class="chapter" data-level="2.1" data-path="D-CES.html"><a href="D-CES.html#background-1"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="D-CES.html"><a href="D-CES.html#when-to-use-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.2</b> When to Use Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="2.3" data-path="D-CES.html"><a href="D-CES.html#general-definition-of-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.3</b> General Definition of Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="2.4" data-path="D-CES.html"><a href="D-CES.html#what-we-assume-when-we-synthesize-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.4</b> What We Assume When We Synthesize Design-Comparable Effect Sizes</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="D-CES.html"><a href="D-CES.html#what-we-assume-when-we-estimate-design-comparable-effect-size"><i class="fa fa-check"></i><b>2.4.1</b> What We Assume When We Estimate Design-Comparable Effect Size</a></li>
<li class="chapter" data-level="2.4.2" data-path="D-CES.html"><a href="D-CES.html#normality"><i class="fa fa-check"></i><b>2.4.2</b> Normality</a></li>
<li class="chapter" data-level="2.4.3" data-path="D-CES.html"><a href="D-CES.html#homogeneity-of-variance"><i class="fa fa-check"></i><b>2.4.3</b> Homogeneity of Variance</a></li>
<li class="chapter" data-level="2.4.4" data-path="D-CES.html"><a href="D-CES.html#appropriate-structural-model"><i class="fa fa-check"></i><b>2.4.4</b> Appropriate Structural Model</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="D-CES.html"><a href="D-CES.html#modeling-options-for-design-comparable-effect-size-estimation"><i class="fa fa-check"></i><b>2.5</b> Modeling Options for Design-comparable Effect Size Estimation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html"><i class="fa fa-check"></i><b>3</b> Illustration of Design-Comparable Effect Sizes When No Trends Are Assumed</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies"><i class="fa fa-check"></i><b>3.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="3.2" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#details-of-the-no-trend-models-for-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>3.2</b> Details of the No Trend Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="3.3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies"><i class="fa fa-check"></i><b>3.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-1-multiple-baseline-study-by-case1992improving"><i class="fa fa-check"></i><b>3.3.1</b> Example 1: Multiple Baseline Study by <span class="citation">Case et al. (1992)</span></a></li>
<li class="chapter" data-level="3.3.2" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-2-multiple-baseline-study-by-peltier2020effects"><i class="fa fa-check"></i><b>3.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Peltier et al. (2020)</span></a></li>
<li class="chapter" data-level="3.3.3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-3-replicated-abab-design-by-lambert2006effects"><i class="fa fa-check"></i><b>3.3.3</b> Example 3: Replicated ABAB Design by <span class="citation">Lambert et al. (2006)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#estimating-the-design-comparable-effect-size-for-the-group-studies"><i class="fa fa-check"></i><b>3.4</b> Estimating the Design-Comparable Effect Size for the Group Studies</a></li>
<li class="chapter" data-level="3.5" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#analyzing-the-effect-sizes"><i class="fa fa-check"></i><b>3.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html"><i class="fa fa-check"></i><b>4</b> Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases</a>
<ul>
<li class="chapter" data-level="4.1" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies-1"><i class="fa fa-check"></i><b>4.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="4.2" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#details-of-the-models-for-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>4.2</b> Details of the Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="4.3" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies-1"><i class="fa fa-check"></i><b>4.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#example-1-multiple-baselise-study-by-gunning2003psychological"><i class="fa fa-check"></i><b>4.3.1</b> Example 1: Multiple Baselise Study by <span class="citation">Gunning &amp; Espie (2003)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#example-2-multiple-baseline-study-by-delemere2018parentimplemented"><i class="fa fa-check"></i><b>4.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Delemere &amp; Dounavi (2018)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-group-studies-1"><i class="fa fa-check"></i><b>4.4</b> Estimating the Design-Comparable Effect Size for the Group Studies</a></li>
<li class="chapter" data-level="4.5" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#analyzing-the-effect-sizes-1"><i class="fa fa-check"></i><b>4.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html"><i class="fa fa-check"></i><b>5</b> Illustration of Design-Comparable Effect Sizes When Assuming Trends in Baseline and Different Trends in Treatment</a>
<ul>
<li class="chapter" data-level="5.1" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies-2"><i class="fa fa-check"></i><b>5.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="5.2" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#details-of-the-models-for-design-comparable-effect-sizes-1"><i class="fa fa-check"></i><b>5.2</b> Details of the Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="5.3" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies-2"><i class="fa fa-check"></i><b>5.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#example-1-multiple-probe-study-by-datchuk2016writing"><i class="fa fa-check"></i><b>5.3.1</b> Example 1: Multiple Probe Study by <span class="citation">Datchuk (2016)</span></a></li>
<li class="chapter" data-level="5.3.2" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#example-2-multiple-baseline-study-by-rodgers2021effects"><i class="fa fa-check"></i><b>5.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Rodgers et al. (2021)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#estimating-the-design-comparable-effect-size-for-the-group-study"><i class="fa fa-check"></i><b>5.4</b> Estimating the Design-Comparable Effect Size for the Group Study</a></li>
<li class="chapter" data-level="5.5" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#analyzing-the-effect-sizes-2"><i class="fa fa-check"></i><b>5.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="raw-data.html"><a href="raw-data.html"><i class="fa fa-check"></i><b>6</b> Introduction to Multilevel Modeling of Raw Participant Data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="raw-data.html"><a href="raw-data.html#background-2"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="raw-data.html"><a href="raw-data.html#when-to-use-multilevel-models-of-the-raw-data"><i class="fa fa-check"></i><b>6.2</b> When to Use Multilevel Models of the Raw Data</a></li>
<li class="chapter" data-level="6.3" data-path="raw-data.html"><a href="raw-data.html#what-we-assume-with-multilevel-models-of-the-raw-data"><i class="fa fa-check"></i><b>6.3</b> What We Assume with Multilevel Models of the Raw Data</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="raw-data.html"><a href="raw-data.html#within-case-model-assumptions"><i class="fa fa-check"></i><b>6.3.1</b> Within-Case Model Assumptions</a></li>
<li class="chapter" data-level="6.3.2" data-path="raw-data.html"><a href="raw-data.html#case-similarity-assumptions"><i class="fa fa-check"></i><b>6.3.2</b> Case Similarity Assumptions</a></li>
<li class="chapter" data-level="6.3.3" data-path="raw-data.html"><a href="raw-data.html#study-similarity-assumptions"><i class="fa fa-check"></i><b>6.3.3</b> Study Similarity Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="raw-data.html"><a href="raw-data.html#comparison-to-other-synthesis-approaches"><i class="fa fa-check"></i><b>6.4</b> Comparison to Other Synthesis Approaches</a></li>
<li class="chapter" data-level="6.5" data-path="raw-data.html"><a href="raw-data.html#multilevel-modeling-options-for-synthesizing-single-case-research"><i class="fa fa-check"></i><b>6.5</b> Multilevel Modeling Options for Synthesizing Single-Case Research</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html"><i class="fa fa-check"></i><b>7</b> Introduction to Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#background-3"><i class="fa fa-check"></i><b>7.1</b> Background</a></li>
<li class="chapter" data-level="7.2" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#when-to-use-case-specific-effect-sizes"><i class="fa fa-check"></i><b>7.2</b> When to Use Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="7.3" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-case-specific-effect-sizes"><i class="fa fa-check"></i><b>7.3</b> Assumptions and Limitations of Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="7.4" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-nonoverlap-indices"><i class="fa fa-check"></i><b>7.4</b> Assumptions and Limitations of Nonoverlap Indices</a></li>
<li class="chapter" data-level="7.5" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-standardized-mean-differences"><i class="fa fa-check"></i><b>7.5</b> Assumptions and Limitations of Standardized Mean Differences</a></li>
<li class="chapter" data-level="7.6" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-percentage-change-indices-and-log-response-ratios"><i class="fa fa-check"></i><b>7.6</b> Assumptions and Limitations of Percentage Change Indices and Log Response Ratios</a></li>
<li class="chapter" data-level="7.7" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-percent-of-goal-obtained"><i class="fa fa-check"></i><b>7.7</b> Assumptions and Limitations of Percent of Goal Obtained</a></li>
<li class="chapter" data-level="7.8" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#case-specific-effect-size-options-for-synthesizing-single-case-research"><i class="fa fa-check"></i><b>7.8</b> Case-Specific Effect Size Options for Synthesizing Single-Case Research</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html"><i class="fa fa-check"></i><b>8</b> Application of Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="8.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#selecting-case-specific-effect-sizes-for-the-single-case-studies"><i class="fa fa-check"></i><b>8.1</b> Selecting Case-Specific Effect Sizes for the Single-Case Studies</a></li>
<li class="chapter" data-level="8.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#estimating-the-case-specific-effect-sizes-for-the-included-aac-intervention-studies"><i class="fa fa-check"></i><b>8.2</b> Estimating the Case-Specific Effect Sizes for the Included AAC Intervention Studies</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#entering-the-data-into-excel"><i class="fa fa-check"></i><b>8.2.1</b> Entering the Data into Excel</a></li>
<li class="chapter" data-level="8.2.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#accessing-the-app"><i class="fa fa-check"></i><b>8.2.2</b> Accessing the App</a></li>
<li class="chapter" data-level="8.2.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#loading-the-data-into-the-app"><i class="fa fa-check"></i><b>8.2.3</b> Loading the Data into the App</a></li>
<li class="chapter" data-level="8.2.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#defining-the-variable-within-the-app"><i class="fa fa-check"></i><b>8.2.4</b> Defining the Variable within the App</a></li>
<li class="chapter" data-level="8.2.5" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#examining-the-graphs-within-the-app"><i class="fa fa-check"></i><b>8.2.5</b> Examining the Graphs within the App</a></li>
<li class="chapter" data-level="8.2.6" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#estimating-the-effect-sizes-within-the-app"><i class="fa fa-check"></i><b>8.2.6</b> Estimating the Effect Sizes within the App</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#syntex-for-r"><i class="fa fa-check"></i><b>8.3</b> Syntex for R</a></li>
<li class="chapter" data-level="8.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#examining-the-alignment-of-the-case-specific-effect-sizes-with-our-visual-analysis"><i class="fa fa-check"></i><b>8.4</b> Examining the Alignment of the Case-Specific Effect Sizes with our Visual Analysis</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#nap"><i class="fa fa-check"></i><b>8.4.1</b> NAP</a></li>
<li class="chapter" data-level="8.4.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#smd-results"><i class="fa fa-check"></i><b>8.4.2</b> SMD Results</a></li>
<li class="chapter" data-level="8.4.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#lrri-results"><i class="fa fa-check"></i><b>8.4.3</b> LRRi Results</a></li>
<li class="chapter" data-level="8.4.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#pogomuparrow"><i class="fa fa-check"></i><b>8.4.4</b> PoGO<sub>M<span class="math inline">\(\uparrow\)</span></sub></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#averaging-the-case-specific-effect-sizes"><i class="fa fa-check"></i><b>8.5</b> Averaging the Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#fixed-effects-meta-analysis"><i class="fa fa-check"></i><b>8.5.1</b> Fixed Effects Meta-Analysis</a></li>
<li class="chapter" data-level="8.5.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#random-effects-meta-analysis"><i class="fa fa-check"></i><b>8.5.2</b> Random Effects Meta-Analysis</a></li>
<li class="chapter" data-level="8.5.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#further-directions-for-synthesizing-case-specific-effect-sizes"><i class="fa fa-check"></i><b>8.5.3</b> Further Directions for Synthesizing Case-Specific Effect Sizes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methods Guide for Effect Estimation and Synthesis of Single-Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="illustrate-D-CES-Ttrends" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases<a href="illustrate-D-CES-Ttrends.html#illustrate-D-CES-Ttrends" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This chapter illustrates the computation of design-comparable effect sizes in contexts where one assumes trends in the treatment phase only, with no trends in the baseline phase. Using data from two multiple baseline studies and a group study, we provide step-by-step instructions for selecting design-comparable effect sizes for the single-case studies and estimating them using the <em>scdhlm</em> app. We also briefly discuss estimating the effect size for the group study and synthesizing the effect sizes across the single-case and group and design studies.</p>
<p>In this chapter, we demonstrate the computation of design-comparable effect sizes using models with trends in the treatment phase(s) online (i.e., no baseline trend), as represented by Models 3 and 4 in Figure <a href="D-CES.html#fig:DC-ES-flow-chart">2.4</a>. These models assume that: (a) baseline observations of the dependent variable for each case occur at a stable level and (b) intervention leads to a change in both level and <em>trajectory</em> or growth rate in the treatment phase.</p>
<p>Let us consider a hypothetical scenario where we are interested in synthesizing single-case design (SCD) and group design studies that report intervention effects for reducing the amount of time it takes individuals to fall asleep at night (i.e., sleep onset latency). For purposes of illustration, we consider a review comprised of just three studies, including two multiple baseline designs and one group design. The first SCD study <span class="citation">(<a href="#ref-delemere2018ParentImplemented">Delemere &amp; Dounavi, 2018</a>)</span> investigated the effects of two parent-implemented interventions (positive routines versus fading routines) on reducing sleep onset latency for six child participants with autism. Our second included SCD study, <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span>, evaluated the effects of a sleep intervention on reducing the sleep latency of seven adult participants with intellectual disabilities. Our third study, a group design by <span class="citation">Montgomery (<a href="#ref-montgomery2004relative">2004</a>)</span>, compared the efficacy of two sleep intervention delivery methods (face-to-face or booklet) for 66 children with learning disabilities (aged 2–8 years) randomly assigned to either treatment or waitlist control groups.</p>
<p>We recommend that researchers use the decision rules in Figure <a href="intro.html#fig:synthesis-flow-chart">1.1</a> to select a method to estimate and synthesize effects, and to consider design-comparable effect sizes when the purpose is to aggregate effects across SCD and group design studies. For Models 3 and 4 and using the aforementioned set of studies for our hypothetical synthesis, we break down the process of model selection and estimation into four steps:
1. Selecting a design-comparable effect size for the SCD studies.
2. Estimating the design-comparable effect size for the SCD studies using the <em>scdhlm</em> app <span class="citation">(<a href="#ref-pustejovsky2021scdhlm">Pustejovsky et al., 2021</a>)</span>.
3. Estimating the effect sizes for the group studies.
4. Synthesizing the effect sizes across single-case and group studies.</p>
<p>We focus on the first two steps because guidance and illustrations of methods for group studies are readily available from other sources <span class="citation">(<a href="#ref-borenstein2021introduction">Borenstein et al., 2021</a>; <a href="#ref-cooper2019handbook">H. Cooper et al., 2019</a>)</span>.</p>
<div id="selecting-a-design-comparable-effect-size-for-the-single-case-studies-1" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Selecting a Design-Comparable Effect Size for the Single-Case Studies<a href="illustrate-D-CES-Ttrends.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We begin by using the decision rules in Figure <a href="D-CES.html#fig:DC-ES-flow-chart">2.4</a> to guide our selection of an appropriate design-comparable effect size. Across the studies, we use our knowledge of the population, context, and outcome of interest to inform any assumptions about the presence or absence of trends in either baseline and/or treatment phases. For our included studies, we assume that all participants generally have stable but high levels of behavior impeding a healthy nighttime routine (e.g., long latency to onset of sleep, frequent nighttime awakenings, etc.). We also assume no therapeutic trend in the baseline phase for each participant because otherwise there would be no need for the participants to receive the intervention. Further, we postulate that intervention will result in improved sleep behavior over time, as noted by a reduction in sleep problems in the treatment phase. Because we predict trend in only the treatment phase but not the baseline phase, we tentatively consider using Model 3 or Model 4 (see Figure <a href="D-CES.html#fig:DC-ES-flow-chart">2.4</a>).</p>
<p>Ideally, we would make the choice between Model 3 and Model 4 based on a logic model and a priori expectation of treatment effect variation (or lack thereof) within and across cases. For example, if we hypothesize that treatment effects do not vary from one case to the next, we will specify our design-comparable effect size using Model 3. Alternatively, if we assume that effects do vary across cases, we will use Model 4. For this synthesis, we note that all studies investigated sleep problems in the context of a participant’s own home. Furthermore, primary caregivers delivered the interventions, and we assume they have different learning histories and backgrounds. Therefore, we believe it is reasonable to anticipate some variation in the effect across cases and tentatively select Model 4.</p>
<p>The next step in the selection of design-comparable effect sizes for SCDs requires us to conduct visual inspection of each SCD study graph to see if our trend assumptions hold. We extracted data from the <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span> study and present the multiple baseline across participant graphs in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-MAJ">4.1</a> (three participants who received the bedtime fading intervention) and Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-NMT">4.2</a> (three participants who received the positive routines intervention). In Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003">4.3</a>, we extracted data from the <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span> study and present the multiple baseline design graph for the seven participants with the target outcome of reducing sleep onset. When visually analyzing the graphs, we consider whether the data are reasonably consistent with the homogeneity and normality assumptions underlying any of the models for design-comparable effect sizes. In Figures <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-MAJ">4.1</a>-<a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003">4.3</a>, we observe similar variation between cases and variation across phases within each case and conclude that the assumption of homogeneous level-1 variance is tenable. In addition, we find no severe outlying data to suggest clear departures from non-normality. Therefore, our initial decision to use design-comparable effect sizes appears appropriate.</p>
<div class="figure"><span style="display:block;" id="fig:Delemere-2018-MAJ"></span>
<img src="images/DelemereDounavi2018_MartinAllenJohn.png" alt="Multiple Baseline Data for Martin, Alan, and John (Delemere &amp; Dounavi, 2018)" width="60%" />
<p class="caption">
Figure 4.1: Multiple Baseline Data for Martin, Alan, and John (Delemere &amp; Dounavi, 2018)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Delemere-2018-NMT"></span>
<img src="images/DelemereDounavi2018_NiahmMaryThomas.png" alt="Multiple Baseline Data for Niahm, Mary, and Thomas (Delemere &amp; Dounavi, 2018)" width="60%" />
<p class="caption">
Figure 4.2: Multiple Baseline Data for Niahm, Mary, and Thomas (Delemere &amp; Dounavi, 2018)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003"></span>
<img src="images/Gunning&Espie2003.png" alt="Multiple Baseline Design Data from 7 Participants with the Target Outcome of Reducing Sleep Onset Latency (Gunning &amp; Espie, 2003)" width="60%" />
<p class="caption">
Figure 4.3: Multiple Baseline Design Data from 7 Participants with the Target Outcome of Reducing Sleep Onset Latency (Gunning &amp; Espie, 2003)
</p>
</div>
<p>Next, for our included studies, we consider the appropriateness of Models 3 and 4 that assume no trends in baseline. Visual inspection of the participants’ graphs in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-MAJ">4.1</a> <span class="citation">(<a href="#ref-delemere2018ParentImplemented">Delemere &amp; Dounavi, 2018</a>)</span> appears to reinforce our assumption of no trend in baseline data. Similarly, as shown in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003">4.3</a> <span class="citation">(<a href="#ref-gunning2003Psychological">Gunning &amp; Espie, 2003</a>)</span>, sleep onset latency neither increased nor decreased in the baseline condition for most participants. However, there are some exceptions to baseline stability observed. In Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003">4.3</a>, Case D appears to show some improvement during baseline. In Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-NMT">4.2</a>, Niahm, Mary, and Thomas appear to have worsening sleep problems during the baseline phase. These trends are inconsistent with the typical pattern seen across cases in Figures <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-MAJ">4.1</a> and <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003">4.3</a>. Whether there are truly trends that would continue is questionable. Perhaps the trends are artifacts related to fidelity or reliability of parental data collection, and thus would not continue.</p>
<p>In similar situations, we recommend that researchers reflect upon and reconsider their model selection. Using this specific example, it seems odd to assume that simply enrolling in a study would affect sleep patterns well established within the participant’s home routine. Rather, we find it more reasonable to assume that sleep onset latency for individuals with disabilities would vary around an average level across baseline observations. Therefore, we proceed with Model 4 because most cases in the included studies have baseline data consistent with the expectation of no trend, and because of the ambiguity and questions surrounding the few possible exceptions.</p>
<p>We proceed with visual inspection of observations in the treatment phase after examining baseline phase observations. Across most cases, we note an immediate change in the time it takes participants to fall asleep and a downward trend in treatment phase observations. While there are a few exceptions where participants appear to respond immediately to intervention, the downward trend does not continue across the remainder of the treatment phase (e.g., see Niahm, Mary, and Thomas in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-NMT">4.2</a>). Because the design-comparable effect size assumes a common model across cases and estimates an average effect across the cases, we find it best to select a model that is consistent with the typical and expected pattern. Thus, it appears reasonable to proceed with a model that assumes no trend in baseline conditions and a trend in the treatment phase (i.e., Model 3 or Model 4 from Figure <a href="D-CES.html#fig:DC-ES-flow-chart">2.4</a>.</p>
</div>
<div id="details-of-the-models-for-design-comparable-effect-sizes" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Details of the Models for Design-Comparable Effect Sizes<a href="illustrate-D-CES-Ttrends.html#details-of-the-models-for-design-comparable-effect-sizes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To appreciate how the treatment effect is defined in Models 3 and 4, let us examine the models in more detail. For both Model 3 and Model 4, we can write the within-case model as:
<span class="math display" id="eq:M3M4-L1">\[\begin{equation}
\tag{4.1}
Y_{ij} = \beta_{0j} + \beta_{1j}Tx_{ij} + \beta_{2j}Tx_{ij}\times(Time_{ij}-k_j-D) + e_{ij},
\end{equation}\]</span>
where <span class="math inline">\(Y_{ij}\)</span> is the score on the outcome variable <span class="math inline">\(Y\)</span> at measurement occasion <span class="math inline">\(i\)</span> for case <span class="math inline">\(j\)</span>, <span class="math inline">\(Tx_{ij}\)</span> is dummy coded with a value of <span class="math inline">\(0\)</span> for baseline observations and a value of <span class="math inline">\(1\)</span> for the treatment phase observations, <span class="math inline">\(k_j\)</span> is the last time-point before case <span class="math inline">\(j\)</span> enters the treatment phase, and <span class="math inline">\(D\)</span> is a centering constant that defines the focal time for indexing the treatment effect. The raw score treatment effect for case <span class="math inline">\(j\)</span> is indexed by <span class="math inline">\(\beta_{1j}\)</span>, which is the distance between the treatment phase trend line and the baseline mean at the time where <span class="math inline">\((Time_{ij}-k_j-D)=0\)</span>. In Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-2018-Martin">4.4</a>, we portray the raw score treatment effect for Martin at a time of 5 observations into treatment. If we set <span class="math inline">\(D&lt;5\)</span>, the focal treatment effect would be smaller; if we set <span class="math inline">\(D&gt;5\)</span>, the focal treatment effect would be larger. The other coefficients of the within-case model are <span class="math inline">\(\beta_{0j}\)</span>, which is the mean level of the outcome during baseline for case <span class="math inline">\(j\)</span>, and <span class="math inline">\(\beta_{2j}\)</span>, which is the slope of the treatment phase trend line for case <span class="math inline">\(j\)</span>. The error (<span class="math inline">\(e_{ij}\)</span>) is time-specific and case-specific and assumed normally distributed and first-order autoregressive with variance <span class="math inline">\(\sigma_e^2\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:Delemere-2018-Martin"></span>
<img src="images/DelemereDounavi2018_Martin.png" alt="Martin's Treatment Effect Five Observations into Treatment (Delemere &amp; Dounavi, 2018)" width="75%" />
<p class="caption">
Figure 4.4: Martin’s Treatment Effect Five Observations into Treatment (Delemere &amp; Dounavi, 2018)
</p>
</div>
<p>Because the effect varies over time in the treatment phase and we estimate it at a specific focal time (i.e., when <span class="math inline">\((Time_{ij}-k_j-D)=0\)</span>), it is important for us to consider what focal time we should select. For example, is it better to estimate the effect at the beginning of the treatment phase or between 3-10 observations into the treatment phase? Researchers should carefully consider their focal time selection by examining patterns in the typical treatment phase length in each SCD and group design study. For example, we chose to estimate the effect for the SCD studies 10 observations into the treatment phase for two reasons. First, 10 observations into treatment is closely aligned with the group design study time at posttest. Second, SCD studies in this area, like those used for this illustration, tend to have at least 10 treatment observations; a single exception in our studies can be seen for John <span class="citation">(<a href="#ref-delemere2018ParentImplemented">Delemere &amp; Dounavi, 2018</a>)</span>, who has only seven treatment observations.</p>
<p>For Model 3, the between-case model specification is:
<span class="math display" id="eq:M3-L2-intercept">\[\begin{equation}
\tag{4.2}
\beta_{0j} = \gamma_{00} + u_{0j}
\end{equation}\]</span>
<span class="math display" id="eq:M3-L2-slope-trt">\[\begin{equation}
\tag{4.3}
\beta_{1j} = \gamma_{10}
\end{equation}\]</span>
<span class="math display" id="eq:M3-L2-slope-interaction">\[\begin{equation}
\tag{4.4}
\beta_{2j} = \gamma_{20}
\end{equation}\]</span>
where <span class="math inline">\(\gamma_{00}\)</span> is the across- case average baseline mean and <span class="math inline">\(u_{0j}\)</span> is a case-specific error, which accounts for variation between cases in their mean baseline levels and is assumes assumed to follow a normal distribution with variance <span class="math inline">\(\sigma_{u_0}^2\)</span>. We assume the same average treatment effect (<span class="math inline">\(\gamma_{10}\)</span>) and the average slope for the treatment phase (<span class="math inline">\(\gamma_{20}\)</span>) across cases. Thus, there are no error terms in the latter two equations. We show the design-comparable effect size in Equation <a href="illustrate-D-CES-Ttrends.html#eq:M3-SMD">(4.5)</a>, defined as the average raw score treatment effect (<span class="math inline">\(\gamma_{10}\)</span>) divided by a standard deviation (SD) comparable to the SD used in group design studies.
<span class="math display" id="eq:M3-SMD">\[\begin{equation}
\tag{4.5}
\delta = \frac{\gamma_{10}}{\sqrt{\sigma_{u_0}^2 + \sigma_e^2}},
\end{equation}\]</span></p>
<p>Model 4 is specified in a very similar way as Model 3, apart from adding error terms (<span class="math inline">\(u_{1j}\)</span> and <span class="math inline">\(u_{2j}\)</span>) to the final two equations to account for between-case variation in the treatment effect and treatment phase slopes. More specifically:
<span class="math display" id="eq:M4-L1">\[\begin{equation}
\tag{4.6}
Y_{ij} = \beta_{0j} + \beta_{1j}Tx_{ij} + \beta_{2j}Tx_{ij}\times(Time_{ij}-k_j-D) + e_{ij},
&lt;!-- MC: I use Tx instead of Txt and use e_{ij} instead of r_{ij} in Equation 4.6 in the word doc.--&gt;
\end{equation}\]</span>
<span class="math display" id="eq:M4-L2-intercept">\[\begin{equation}
\tag{4.7}
\beta_{0j} = \gamma_{00} + u_{0j}
\end{equation}\]</span>
<span class="math display" id="eq:M4-L2-slope-trt">\[\begin{equation}
\tag{4.8}
\beta_{1j} = \gamma_{10} + u_{1j}
\end{equation}\]</span>
<span class="math display" id="eq:M4-L2-slope-interaction">\[\begin{equation}
\tag{4.9}
\beta_{2j} = \gamma_{20} + u_{2j}
\end{equation}\]</span></p>
<p>Again, the across-case average baseline mean is <span class="math inline">\(\gamma_{00}\)</span> and the average raw score treatment effect at the focal time is <span class="math inline">\(\gamma_{10}\)</span>. The case-specific errors (<span class="math inline">\(u_{0j}, u_{1j}, u_{2j}\)</span>), which account for between-case differences in baseline level and response to treatment, are assumed multivariate normal with covariance
<span class="math inline">\(\Sigma_u = \begin{bmatrix} \sigma_{u_0}^2 &amp; &amp; \\ \sigma_{u_1u_0} &amp; \sigma_{u_1}^2 &amp; \\ \sigma_{u_2u_0} &amp; \sigma_{u_2u_1} &amp; \sigma_{u_2}^2\\ \end{bmatrix}\)</span>.
Note that one could opt for a model that is intermediate between Model 3 and Model 4, by including only <span class="math inline">\(u_{1j}\)</span> or <span class="math inline">\(u_{2j}\)</span>, and thereby allowing random variation in either (but not both) the level or slope changes. We proceed with random variability in each, because we think the treatment could lead to both different shifts in level and different treatment phase slopes for different participants. However, the inclusion of three random effects with an unstructured covariance matrix can be challenging to estimate with a limited number of cases. A simpler model with fewer random effects may be preferable if estimation difficulties arise.</p>
<p>Regardless of whether we allow both <span class="math inline">\(\beta_{1j}\)</span> and <span class="math inline">\(\beta_{2j}\)</span> to vary randomly as shown in Equations <a href="illustrate-D-CES-Ttrends.html#eq:M4-L2-slope-trt">(4.8)</a> and <a href="illustrate-D-CES-Ttrends.html#eq:M4-L2-slope-interaction">(4.9)</a> or allow only one of these effects to vary randomly, we define the design-comparable effect size exactly as in Equation <a href="illustrate-D-CES-Ttrends.html#eq:M3-SMD">(4.5)</a>. This is because the effect size is scaled by the SD of the outcome in the absence of intervention (i.e., during baseline); it is not impacted by assumptions about the between-case variation during the treatment phase.</p>
<p>In the following sections, we will illustrate the estimation of design-comparable effect sizes for the SCD studies using Model 4 based on a priori considerations and the differences noted between cases in their treatment phase slopes. After obtaining the design-comparable effect sizes using Model 4, we repeat the process using Model 3 for several reasons. First, contrasting the models allows us an additional way to examine the empirical support for our chosen model. For instance, visual analyses of the model-implied individual trajectories for Model 4 might show a better fit than those for Model 3. Second, the contrast allows us to examine the sensitivity of the effect size estimates to our selected model. For instance, whether we assume the effect size varies across cases could have little to no effect on the design-comparable effect size estimate. Last, the contrast between Model 3 and Model 4 design-comparable effect sizes allows us to illustrate a method of selecting between models in circumstances where a priori information is not sufficient to select a model.</p>
</div>
<div id="estimating-the-design-comparable-effect-size-for-the-single-case-studies-1" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Estimating the Design-Comparable Effect Size for the Single-Case Studies<a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="example-1-multiple-baselise-study-by-gunning2003psychological" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Example 1: Multiple Baselise Study by <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span><a href="illustrate-D-CES-Ttrends.html#example-1-multiple-baselise-study-by-gunning2003psychological" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can estimate design-comparable effect sizes for any model in Figure <a href="D-CES.html#fig:DC-ES-flow-chart">2.4</a> using a web-based calculator for design-comparable effect sizes <span class="citation">(<a href="#ref-pustejovsky2021scdhlm">Pustejovsky et al., 2021</a>)</span>. The <em>scdhlm</em> app is available at <a href="https://jepusto.shinyapps.io/scdhlm/" class="uri">https://jepusto.shinyapps.io/scdhlm/</a>. To use this app, researchers must store the data in an Excel file (.xlsx), comma delimited file (.csv), or text file (.txt). In addition, the data must include columns for the <em>case identifier</em>, +phase identifier_, <em>session number</em>, and <em>outcome</em>.
Although not required, we suggest that researchers arrange their data columns by order of variable appearance in the <em>scdhlm</em> app, putting the <em>case identifier</em> in the first column, <em>phase identifier</em> in the second column and so on. We present this layout in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-excel">4.5</a>, representing data extracted for the study by <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span>.
In this illustration, for <em>phase identifier</em>, we use <em>b</em> to indicate baseline observations and <em>i</em> to indicate intervention observations. However, researchers can use any other labeling scheme that clearly distinguishes between baseline and intervention conditions (e.g., 0 and 1, respectively). Unlike the <em>phase identifier</em> variable, <em>session number</em> and <em>outcome</em> variables must contain numerical values. We also recommend entering data into the spreadsheet first by case (e.g., enter all the rows of data for the first case before any of the rows of data for the second case), then by <em>session number</em>.</p>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-excel"></span>
<img src="images/excel_GunningEspie2003.png" alt="Snapshot of Spreadsheet Containing Extracted Gunning &amp; Espie (2003) Data" width="60%" />
<p class="caption">
Figure 4.5: Snapshot of Spreadsheet Containing Extracted Gunning &amp; Espie (2003) Data
</p>
</div>
<p>After starting the app, we use the <em>Load</em> tab to load the data file, as illustrated in Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-load">4.6</a>.
<!-- MC: I changed the Figure 23 in the word doc to Figure 4.6 here. -->
The data file could be a .txt or .csv file that includes one dataset or could be an Excel (.xlsx) file that has either one spreadsheet (e.g., a data set for one study), or multiple spreadsheets (one spreadsheet for each of several studies). If using a .xlsx file with multiple spreadsheets, we can select the spreadsheet containing the data for the study of interest from the <em>Load</em> tab. Then, we use the drop-down menus on the right of the screen to indicate the study design (<em>Treatment Reversal</em> versus <em>Multiple Baseline/Multiple Probe across participants</em>) and define which variables in the data set correspond to the case identifier, <em>phase identifier</em>, session, and <em>outcome</em> (see Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-load">4.6</a>).</p>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-load"></span>
<img src="images/app.load_GunningEspie2003.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Load Tab for Gunning &amp; Espie (2003)" width="60%" />
<p class="caption">
Figure 4.6: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Load Tab for Gunning &amp; Espie (2003)
</p>
</div>
<p>After we load our data, we use the <em>Inspect</em> tab to ensure that the raw data imported correctly and mapped to their corresponding variable names (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-inspect-data">4.7</a>). In addition, we can use the Inspect tab to view a graph of the data (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-inspect-graph">4.8</a>). At this point, we recommend that researchers compare these data with the graphed data from the original studies as an additional measure that ensures the study data uploaded to the app correctly (according to the selections on the <em>Load</em> tab). Later, these graphed data can also be checked again for consistency with the tentatively selected model for estimating the design-comparable effect size.</p>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-inspect-data"></span>
<img src="images/app.inspect.data_GunningEspie2003.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Data Tab within the Inspect Tab for Gunning &amp; Espie (2003)" width="60%" />
<p class="caption">
Figure 4.7: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Data Tab within the Inspect Tab for Gunning &amp; Espie (2003)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-inspect-graph"></span>
<img src="images/app.inspect.graph_GunningEspie2003.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Graph Display within the Inspect Tab for Gunning &amp; Espie (2003)" width="60%" />
<p class="caption">
Figure 4.8: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Graph Display within the Inspect Tab for Gunning &amp; Espie (2003)
</p>
</div>
<p>Upon completion of data inspection, we next specify the model for the design-comparable effect size using the <em>Model</em> tab. Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-model">4.9</a> shows the specification for Model 4, the model that assumes no baseline trend, a trend in the treatment phase, and an effect that varies across cases. Specification begins with the <em>Baseline phase</em> section, where we select <em>level</em> under <em>Type of time trend</em> because we assume that there are no time trends in the baseline phases. We then choose to include <em>level</em> as a fixed effect, enabling the model to estimate the average baseline level. We also include <em>level</em> as a random effect so that the baseline level can vary from case to case.</p>
<p>Next, we specify the model for the <em>Treatment phase</em>. In <em>Type of time trend</em>, we choose the option <em>change in linear trend</em> because Models 3 and 4 allow for possible time trends in only the treatment phases, implying that the trend changes across phases. To specify Model 4, we include both <em>change in level</em> and <em>change in linear trend</em> as fixed effects, so that the average trajectory across cases can reflect both an immediate change in level plus a change in the trend.
We also select the option to include <em>change</em> in level as a random effect to allow the shift in level (i.e., treatment effect) to vary across cases. In addition, we opt to allow the <em>change in linear trend</em> to vary from case to case by including it as a random effect. At this point, we have specified the model for the design-comparable effect size that matches Model 4. Note the app allows us to make different potential assumptions about the correlation structure of the session-level errors. Shown are the default options of autoregressive and constant variance across phases. These defaults match the model presented in Equations <a href="illustrate-D-CES-Ttrends.html#eq:M3M4-L1">(4.1)</a> and <a href="illustrate-D-CES-Ttrends.html#eq:M4-L1">(4.6)</a>
<!-- MC: I changed Equations 3.1 and 4.1 to 4.1 and 4.6. -->
and are used because they seem appropriate for this data set.
Also note that at the bottom of the screen (see Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-model">4.9</a>), the <em>scdhlm</em> app provides a graph of the data with trend lines that are based on the specified model (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-model">4.9</a>). We recommend that researchers inspect this graph to ensure that the trend lines fit the data reasonably well. If they do not, it raises questions about the model choice.</p>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-model"></span>
<img src="images/app.model.model4_GunningEspie2003.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 4 Specification for Gunning &amp; Espie (2003)" width="60%" />
<p class="caption">
Figure 4.9: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 4 Specification for Gunning &amp; Espie (2003)
</p>
</div>
<p>For this data set, the a priori identified model provides trajectories that fit the data reasonably well, and thus we proceed to the <em>Effect size</em> tab (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-ES">4.10</a>). There are two sliders in the <em>Hypothetical experimental parameters</em> section above the effect size estimates output: <em>Initial treatment time</em> and <em>Follow-up time</em>. The numbers on each slider refer to the sessions or time points in the data series. Although the app populates times automatically, researchers can manipulate them manually to obtain an effect size estimate at a desired point in time. For models with trends in the baseline phase, it matters where we set the initial time. However, for models without baseline trends, only the distance between the two slider values matters.</p>
<p>We imagine a relatively typical SCD study with a baseline of 5; therefore, we use the sliding scale to set the <em>Initial treatment time</em> for the <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span> study to 5 to represent the last session before initiation of the treatment. Next, we estimate the treatment effect 10 observations into treatment and move the <em>Follow-up time</em> slider to the 15th observation. Given these Model 4 specifications for <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span>, we find that the estimated between-case standardized mean difference 10 observations into treatment is -1.12 with a standard error (SE) of 0.34 and <span class="math inline">\(95\%\)</span> confidence interval (CI) [-1.80, -0.45].</p>
<div class="figure"><span style="display:block;" id="fig:Gunning-2003-ES"></span>
<img src="images/app.ES.model4_GunningEspie2003.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Effect size Tab Showing Model 4 Estimate for Gunning &amp; Espie (2003)" width="75%" />
<p class="caption">
Figure 4.10: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Effect size Tab Showing Model 4 Estimate for Gunning &amp; Espie (2003)
</p>
</div>
<p>Now, if we lacked confidence in the a priori decision to select Model 4 and wanted to explore the Model 3 fit, we can re-run the study data without returning to the <em>Load</em> tab. Instead, we go directly to the <em>Model</em> tab to change our specification. To obtain Model 3, we remove (uncheck) <em>change in level</em> and <em>change in linear trend</em> as random effects, constraining the change in level and change in trend from baseline to treatment to be the same for each case. For Model 3, the estimated effect size is -1.10 with an SE of 0.17 and <span class="math inline">\(95\%\)</span> CI [-1.43, -0.76]. In this case, for the <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span> study, the effect size estimates for both Models are similar. However, with the more restrictive assumptions of Model 3, the CI is narrower. If we had used a model that allowed a change in level to vary randomly, but required a fixed slope change, the estimated effect size would be -1.07 with an SE of 0.28 and 95% CI [-1.63, -0.51].</p>
<p>The <em>Effect size</em> tab (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Gunning-2003-ES">4.10</a>) reports additional information including estimates of other model quantities, information about the model specification, and assumptions used in calculating the design-comparable effect size. The reported degrees of freedom are used by the app in making a small-sample correction to the effect size estimate, analogous to the Hedges’ g correction used with group designs <span class="citation">(<a href="#ref-Hedges1981distribution">Hedges, 1981</a>)</span>. Larger estimated degrees of freedom mean that the denominator of the design-comparable effect size is more precisely estimated, and that the small-sample correction is less consequential. Conversely, small degrees of freedom indicates that the denominator of the effect size is imprecisely estimated, making the small-sample correction more consequential. The reported autocorrelation is the estimate of the correlation between errors at the first level of the model for the same case that differ by one time-point (or session), based on a first-order autoregressive model. The reported intra-class correlation is an estimate of the between-case variance of the outcome as a proportion of the total variation in the outcome (including both between-case and within-case variance) as of the selected <em>Follow-up time</em>. Larger values of the intra-class correlation indicate that more of the variation in the outcome is between participants. The remaining information in the output (<em>Study design</em>, <em>Estimation method</em>, <em>Baseline specification</em>, <em>Treatment specification</em>, <em>Initial treatment time</em>, <em>Follow-up time</em>) describe the model specification and assumptions used in the effect size calculations. The app includes it to allow for reproducibility of the calculations.</p>
</div>
<div id="example-2-multiple-baseline-study-by-delemere2018parentimplemented" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Example 2: Multiple Baseline Study by <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span><a href="illustrate-D-CES-Ttrends.html#example-2-multiple-baseline-study-by-delemere2018parentimplemented" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>After obtaining a design-comparable effect size for the first SCD <span class="citation">(<a href="#ref-gunning2003Psychological">Gunning &amp; Espie, 2003</a>)</span>, we repeat these steps for all other included SCD studies. In our second included SCD study <span class="citation">(<a href="#ref-delemere2018ParentImplemented">Delemere &amp; Dounavi, 2018</a>)</span>, the researchers analyzed two interventions. While we could estimate a separate design-comparable effect size for each, for the purposes of illustrating the computational steps in this chapter, we have pooled the data from the six cases to estimate one design-comparable effect size. To obtain a design-comparable effect size for the <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span> study, we follow the same sequence of steps:
1. Load the data.
2. Inspect the data in both tabular and graphic form.
3. Specify our selected model for the data (see Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-model4">4.11</a> for Model 4).
4. Estimate the design-comparable effect size.</p>
<div class="figure"><span style="display:block;" id="fig:Delemere-model4"></span>
<img src="images/app.model.model4_DelemereDounavi2018.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 4 Specification for Delemere and Dounavi (2018)" width="60%" />
<p class="caption">
Figure 4.11: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 4 Specification for Delemere and Dounavi (2018)
</p>
</div>
<p>Proceeding with Model 4, we use the Effect size tab of the <em>scdhlm</em> app to obtain a design-comparable effect size for the <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span> study. As with the previous example, the effect size will depend on the time into intervention at which we estimate the effect size the focal time (indicated by the <em>scdhlm</em> app variable named <em>Follow-up</em> time). When estimating design-comparable effect sizes for SCD studies, researchers should hold the <em>Follow-up time</em> constant across studies. Therefore, we use the <em>Initial treatment time</em> and <em>Follow-up time</em> sliders at the top of the screen to obtain an estimate of effect 10 observations into treatment (i.e., we set the <em>Initial</em> and <em>Follow-up time</em> sliders to five and 15, respectively). The resulting design-comparable effect size for the <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span> study is -0.70 with an SE of 0.33 and 95% CI [-1.49, 0.09].</p>
<p>Again, if we want to compare these results to those estimated using Model 3, we can go back to the <em>Model</em> tab to change our specification. To obtain Model 3, we remove (uncheck) <em>change in level</em> and <em>change in linear trend</em> as random effects to obtain the same change in level and change in trend from baseline to treatment across cases. We keep all other modeling options the same (e.g., <em>Initial treatment time</em> and <em>Follow-up time</em>). Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-model3">4.12</a> shows the Model 3 specification for the <span class="citation">Delemere &amp; Dounavi (<a href="#ref-delemere2018ParentImplemented">2018</a>)</span> study. The estimated design-comparable effect size is -0.91 with an SE of 0.28 and 95% CI [-1.52, -0.29]. Comparing the fit of the trend lines obtained from Model 4 (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-model4">4.11</a>) to those from Model 3 (Figure <a href="illustrate-D-CES-Ttrends.html#fig:Delemere-model3">4.12</a>), our originally specified Model 4 appears to provide a better fit for the primary study data. Because of this and because Model 4 is more consistent with both our a priori expectations and the data from our other SCD study <span class="citation">(i.e., <a href="#ref-gunning2003Psychological">Gunning &amp; Espie, 2003</a>)</span>, it seems reasonable to proceed with the effect estimate from Model 4 (i.e., -0.70).</p>
<div class="figure"><span style="display:block;" id="fig:Delemere-model3"></span>
<img src="images/app.model.model3_DelemereDounavi2018.png" alt="Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 3 Specification for Delemere and Dounavi (2018)" width="60%" />
<p class="caption">
Figure 4.12: Between-Case Standardized Mean Difference Estimator (scdhlm, v. 0.6.0) Model 3 Specification for Delemere and Dounavi (2018)
</p>
</div>
</div>
</div>
<div id="estimating-the-design-comparable-effect-size-for-the-group-studies-1" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Estimating the Design-Comparable Effect Size for the Group Studies<a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-group-studies-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>After estimating the design-comparable effect size for the included SCD studies, the next step is to estimate a design-comparable effect size for the included group design study. Details on estimating standardized mean difference effect sizes from group studies are readily available from a variety of sources, including Chapter 12 of <em>The Handbook on Research Synthesis and Meta-Analysis</em> <span class="citation">(<a href="#ref-Borenstein2019effect">Borenstein, 2019</a>)</span>, books <span class="citation">(e.g., <a href="#ref-borenstein2021introduction">Borenstein et al., 2021</a>)</span> and journal articles <span class="citation">(e.g., <a href="#ref-Hedges1981distribution">Hedges, 1981</a>, <a href="#ref-Hedges2007effect">2007</a>)</span>. Therefore, we do not demonstrate the step-by-step effect size estimation methods for group design studies in this methods guide. Instead, we summarize the results below.</p>
<p>The included group design study, <span class="citation">Montgomery (<a href="#ref-montgomery2004relative">2004</a>)</span>, reported a randomized trial comparing the efficacy of sleep interventions versus a wait-list control condition for families with children with severe learning disabilities. The researchers assigned participating families to a conventional face-to-face intervention (<span class="math inline">\(n = 20\)</span>), a brief treatment delivered as a booklet (<span class="math inline">\(n = 22\)</span>), or a wait-list control condition (<span class="math inline">\(n = 24\)</span>). At posttest, the researchers compared participants’ composite sleep disturbance score (derived from parent reports) across groups, with higher scores corresponding to more severe sleep disturbance. For purposes of effect size calculations, we pooled the results from the face-to-face and booklet intervention conditions. Based on the post-treatment means and standard deviations <span class="citation">(<a href="#ref-montgomery2004relative">Montgomery, 2004</a>, Table 1)</span>, the standardized mean difference in sleep onset at the end of intervention was -1.52, with an SE of 0.29. This effect size estimate is based on Hedges’ g, which corrects for small sample size bias.</p>
</div>
<div id="analyzing-the-effect-sizes-1" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Analyzing the Effect Sizes<a href="illustrate-D-CES-Ttrends.html#analyzing-the-effect-sizes-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As a final step, we synthesize the effect sizes across both SCD and group design studies. A variety of tools and approaches are available to researchers depending on the goals of their synthesis. For example, researchers can: (a) create graphical displays that show the effect size for each study along with its CI, (b) report an overall average effect size and CI by averaging effect sizes across studies and, (c) examine the extent of effect size variation across studies, (d) explore potential moderators of the effects, and (e) examine the effect sizes for evidence of publication bias. Because the use of design-comparable effect size for the SCD studies produces effect estimates that are like the commonly used standardized mean difference effect sizes from group studies, researchers can accomplish these goals using the methods already established for group design studies.
Details on these methods are readily available elsewhere <span class="citation">(e.g., <a href="#ref-borenstein2021introduction">Borenstein et al., 2021</a>; <a href="#ref-cooper2019handbook">H. Cooper et al., 2019</a>)</span>. We illustrate the averaging of the effect sizes from our studies here using a fixed effect meta-analysis, consistent with the approach used in What Works Clearinghouse intervention reports <span class="citation">(<a href="#ref-whatworksclearinghouse2020What">What Works Clearinghouse, 2020b</a>)</span>.</p>
<p>Table <a href="illustrate-D-CES-Ttrends.html#tab:ES-est-chapter4">4.1</a> reports the effect size estimates, SEs, and fixed effect meta-analysis calculations for the example studies. The top panel uses the design-comparable effect size results for SCD studies based on Model 4. As a sensitivity analysis, the bottom panel presents the results based on Model 3. Note that the effect size estimate from the group design study is the same in both panels. In fixed effect meta-analysis, the overall average effect size estimate is a weighted average of the effect size estimates from the individual studies, with weights proportional to the inverse of the sampling variance (squared SE) of each effect size estimate. Further, the SE of the overall effect size is the square root of the inverse of the total weight.</p>
<p>Column C of Table <a href="illustrate-D-CES-Ttrends.html#tab:ES-est-chapter4">4.1</a> reports the inverse-variance weight assigned to each of the studies, with the percentage of the total weight listed in parentheses. In the top panel based on Model 4, the effect size estimate from the group design study receives <span class="math inline">\(40\%\)</span> of the total weight, while the effect size estimates from the SCD studies receive <span class="math inline">\(29\%\)</span> and <span class="math inline">\(31\%\)</span> of the total weight, respectively. The total inverse variance weight is 29.72. The overall average effect size estimate based on Model 4 is -1.15 with an SE of 0.18<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> and an approximate 95% CI [-1.51, -0.79]. The <em>Q</em>-test for heterogeneity is not significant, <span class="math inline">\(Q(2) = 3.50\)</span>, <span class="math inline">\(p = .174\)</span>, indicating that the included effect size estimates are consistent with the possibility that all studies were estimating a common effect size parameter. Interestingly, in this example, the effect size estimate from the group design is larger in magnitude than the effect size estimates from the SCD studies.</p>
<table class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-est-chapter4">Table 4.1: </span>Fixed Effect Meta-Analysis Calculations for
Example Sleep Intervention Studies
</caption>
<thead>
<tr>
<th style="text-align:left;">
Study
</th>
<th style="text-align:center;">
Effect Size Estimate (A)
</th>
<th style="text-align:center;">
Standard Error (B)
</th>
<th style="text-align:center;">
Inverse-variance Weight (%) (C)
</th>
</tr>
</thead>
<tbody>
<tr grouplength="4">
<td colspan="4" style="border-bottom: 0;">
<strong>Model 4</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Gunning &amp; Espie (2003)
</td>
<td style="text-align:center;">
-1.12
</td>
<td style="text-align:center;">
0.34
</td>
<td style="text-align:center;">
8.65 (29.1)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Delemere &amp; Dounavi (2018)
</td>
<td style="text-align:center;">
-0.70
</td>
<td style="text-align:center;">
0.33
</td>
<td style="text-align:center;">
9.18 (30.9)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Montgomery et al. (2004)
</td>
<td style="text-align:center;">
-1.52
</td>
<td style="text-align:center;">
0.29
</td>
<td style="text-align:center;">
11.89 (40.0)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Fixed effect meta-analysis
</td>
<td style="text-align:center;">
-1.15
</td>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
29.72 (100)
</td>
</tr>
<tr grouplength="4">
<td colspan="4" style="border-bottom: 0;">
<strong>Model 3</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Gunning &amp; Espie (2003)
</td>
<td style="text-align:center;">
-1.10
</td>
<td style="text-align:center;">
0.17
</td>
<td style="text-align:center;">
34.60 (58.4)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Delemere &amp; Dounavi (2018)
</td>
<td style="text-align:center;">
-0.91
</td>
<td style="text-align:center;">
0.28
</td>
<td style="text-align:center;">
12.76 (21.5)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Montgomery et al. (2004)
</td>
<td style="text-align:center;">
-1.52
</td>
<td style="text-align:center;">
0.29
</td>
<td style="text-align:center;">
11.89 (20.1)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Fixed effect meta-analysis
</td>
<td style="text-align:center;">
-1.14
</td>
<td style="text-align:center;">
0.13
</td>
<td style="text-align:center;">
59.25 (100)
</td>
</tr>
</tbody>
</table>
<p>The bottom panel of Table <a href="illustrate-D-CES-Ttrends.html#tab:ES-est-chapter4">4.1</a> reports the same calculations but using the design-comparable effect size estimates based on Model 3 for the two SCD studies. The most notable difference is that Model 3 more precisely estimates the design-comparable effect size for the <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span>, resulting in more weight (<span class="math inline">\(58\%\)</span>) assigned in the fixed effect meta-analysis. For Model 3, the overall average effect size is nearly identical to that obtained for Model 4 (-1.14), but the substantially smaller Model 3 design-comparable effect size for the <span class="citation">Gunning &amp; Espie (<a href="#ref-gunning2003Psychological">2003</a>)</span> study results in an SE of 0.13 and <span class="math inline">\(95\%\)</span> CI [-1.40, -0.89].</p>
<p>In fixed effect meta-analysis, the overall average effect size estimate is a summary of the effect size estimates across the included studies, which are treated as fixed. Therefore, the SE and CI in fixed effect meta-analysis take into account the uncertainty in the process of estimating the effect sizes in each of the individual studies, but they do not account for uncertainty in the process of identifying studies for inclusion in the meta-analysis <span class="citation">(<a href="#ref-konstantopoulos2019statistically">Konstantopoulos &amp; Hedges, 2019</a>; <a href="#ref-Rice_Higgins_Lumley_2018">Rice et al., 2018</a>)</span>. Consequently, they do not provide a basis for generalization beyond the included studies. When conducting syntheses of larger bodies of literature—and especially of studies with heterogeneous populations, design features, or dependent effect sizes—researchers will often prefer to use random effects models <span class="citation">(<a href="#ref-Hedges_Vevea_1998">Hedges &amp; Vevea, 1998</a>)</span> or their further extensions <span class="citation">(<a href="#ref-PustejovskyTipton2021">Pustejovsky &amp; Tipton, 2021</a>; <a href="#ref-van2013three">Van den Noortgate et al., 2013</a>)</span>.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-Borenstein2019effect" class="csl-entry">
Borenstein, M. (2019). Effect sizes for continuous data. In H. M. Cooper, L. V. Hedges, &amp; J. C. Valentine (Eds.), <em>The <span>Handbook</span> of <span>Research Synthesis</span> and <span>Meta-Analysis</span></em>. <span>Russell Sage Foundation</span>.
</div>
<div id="ref-borenstein2021introduction" class="csl-entry">
Borenstein, M., Hedges, L. V., Higgins, J. P. T., &amp; Rothstein, H. R. (2021). <em>Introduction to <span>Meta-Analysis</span></em>. <span>John Wiley &amp; Sons, Ltd</span>.
</div>
<div id="ref-cooper2019handbook" class="csl-entry">
Cooper, H., Hedges, L. V., &amp; Valentine, J. C. (2019). <em>The handbook of research synthesis and meta-analysis</em>. Russell Sage Foundation.
</div>
<div id="ref-delemere2018ParentImplemented" class="csl-entry">
Delemere, E., &amp; Dounavi, K. (2018). Parent-<span>Implemented Bedtime Fading</span> and <span>Positive Routines</span> for <span>Children</span> with <span>Autism Spectrum Disorders</span>. <em>Journal of Autism and Developmental Disorders</em>, <em>48</em>(4), 1002–1019. <a href="https://doi.org/10.1007/s10803-017-3398-4">https://doi.org/10.1007/s10803-017-3398-4</a>
</div>
<div id="ref-gunning2003Psychological" class="csl-entry">
Gunning, M. J., &amp; Espie, C. A. (2003). Psychological treatment of reported sleep disorder in adults with intellectual disability using a multiple baseline design. <em>Journal of Intellectual Disability Research</em>, <em>47</em>(3), 191–202. <a href="https://doi.org/10.1046/j.1365-2788.2003.00461.x">https://doi.org/10.1046/j.1365-2788.2003.00461.x</a>
</div>
<div id="ref-Hedges1981distribution" class="csl-entry">
Hedges, L. V. (1981). Distribution theory for <span>Glass</span>’s estimator of effect size and related estimators. <em>Journal of Educational Statistics</em>, <em>6</em>(2), 107–128.
</div>
<div id="ref-Hedges2007effect" class="csl-entry">
Hedges, L. V. (2007). Effect sizes in cluster-randomized designs. <em>Journal of Educational and Behavioral Statistics</em>, <em>32</em>(4), 341–370. <a href="https://doi.org/10.3102/1076998606298043">https://doi.org/10.3102/1076998606298043</a>
</div>
<div id="ref-Hedges_Vevea_1998" class="csl-entry">
Hedges, L. V., &amp; Vevea, J. L. (1998). Fixed- and random-effects models in meta-analysis. <em>Psychological Methods</em>, <em>3</em>(4), 486–504. <a href="https://doi.org/10.1037/1082-989X.3.4.486">https://doi.org/10.1037/1082-989X.3.4.486</a>
</div>
<div id="ref-konstantopoulos2019statistically" class="csl-entry">
Konstantopoulos, S., &amp; Hedges, L. V. (2019). Statistically analyzing effect sizes: Fixed-and random-effects models. In H. Cooper Harris &amp; J. C. Valentine (Eds.), <em>The handbook of research synthesis and meta-analysis</em> (3rd Edition, pp. 246–280). Russell Sage Foundation.
</div>
<div id="ref-montgomery2004relative" class="csl-entry">
Montgomery, P. (2004). The relative efficacy of two brief treatments for sleep problems in young learning disabled (mentally retarded) children: A randomised controlled trial. <em>Archives of Disease in Childhood</em>, <em>89</em>(2), 125–130. <a href="https://doi.org/10.1136/adc.2002.017202">https://doi.org/10.1136/adc.2002.017202</a>
</div>
<div id="ref-pustejovsky2021scdhlm" class="csl-entry">
Pustejovsky, J. E., Chen, M., &amp; Hamilton, B. (2021). <em>Scdhlm: <span>A</span> web-based calculator for between-case standardized mean differences</em>.
</div>
<div id="ref-PustejovskyTipton2021" class="csl-entry">
Pustejovsky, J. E., &amp; Tipton, E. (2021). Meta-analysis with robust variance estimation: Expanding the range of working models. <em>Prevention Science</em>. <a href="https://doi.org/10.1007/s11121-021-01246-3">https://doi.org/10.1007/s11121-021-01246-3</a>
</div>
<div id="ref-Rice_Higgins_Lumley_2018" class="csl-entry">
Rice, K., Higgins, J. P. T., &amp; Lumley, T. (2018). A re-evaluation of fixed effect(s) meta-analysis. <em>Journal of the Royal Statistical Society Series A: Statistics in Society</em>, <em>181</em>(1), 205–227. <a href="https://doi.org/10.1111/rssa.12275">https://doi.org/10.1111/rssa.12275</a>
</div>
<div id="ref-van2013three" class="csl-entry">
Van den Noortgate, W., López-López, J. A., Marı́n-Martı́nez, F., &amp; Sánchez-Meca, J. (2013). Three-level meta-analysis of dependent effect sizes. <em>Behavior Research Methods</em>, <em>45</em>, 576–594. <a href="https://doi.org/10.3758/s13428-012-0261-6">https://doi.org/10.3758/s13428-012-0261-6</a>
</div>
<div id="ref-whatworksclearinghouse2020What" class="csl-entry">
What Works Clearinghouse. (2020b). <em>What <span>Works Clearinghouse Standards Handbook</span></em> (Version 4.1). <span>U.S. Department of Education, Institute of Education Sciences, National Center for Education Evaluation and Regional Assistance.</span>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>The SE of the overall effect size is the square root of the inverse of the total weight.<a href="illustrate-D-CES-Ttrends.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="illustrate-D-CES.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="illustrate-D-CES-Btrends.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SCD-Methods-Guide.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
