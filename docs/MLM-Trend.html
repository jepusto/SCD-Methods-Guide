<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Illustration of Multilevel Modeling When No Trends Are Assumed | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Illustration of Multilevel Modeling When No Trends Are Assumed | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="jepusto/SCD-Methods-Guide" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Illustration of Multilevel Modeling When No Trends Are Assumed | Methods Guide for Effect Estimation and Synthesis of Single-Case Studies" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  



<meta name="date" content="2023-12-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="MLM-NoTrend.html"/>
<link rel="next" href="intro-case-specific-es.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Synthesis of Single-Case Designs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Authors</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#citation"><i class="fa fa-check"></i>Citation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#datasets"><i class="fa fa-check"></i>Datasets</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Approaches for Estimation and Synthesis of Single-Case Studies</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#purpose-of-the-methods-guide"><i class="fa fa-check"></i><b>1.2</b> Purpose of the Methods Guide</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#study-quality"><i class="fa fa-check"></i><b>1.3</b> Study Quality</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#selecting-an-approach-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.4</b> Selecting an Approach for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#design-comparable-effect-sizes"><i class="fa fa-check"></i><b>1.5</b> Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#case-specific-effect-sizes"><i class="fa fa-check"></i><b>1.6</b> Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#multilevel-modeling-of-individual-participant-interrupted-time-series-data"><i class="fa fa-check"></i><b>1.7</b> Multilevel Modeling of Individual Participant Interrupted Time-Series Data</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#summary-of-options-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.8</b> Summary of Options for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#limitations-in-selecting-an-approach-for-effect-estimation-and-synthesis"><i class="fa fa-check"></i><b>1.9</b> Limitations in Selecting an Approach for Effect Estimation and Synthesis</a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#structure-of-the-methods-guide"><i class="fa fa-check"></i><b>1.10</b> Structure of the Methods Guide</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="D-CES.html"><a href="D-CES.html"><i class="fa fa-check"></i><b>2</b> Introduction to Design-Comparable Effect Sizes</a>
<ul>
<li class="chapter" data-level="2.1" data-path="D-CES.html"><a href="D-CES.html#background-1"><i class="fa fa-check"></i><b>2.1</b> Background</a></li>
<li class="chapter" data-level="2.2" data-path="D-CES.html"><a href="D-CES.html#when-to-use-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.2</b> When to Use Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="2.3" data-path="D-CES.html"><a href="D-CES.html#general-definition-of-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.3</b> General Definition of Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="2.4" data-path="D-CES.html"><a href="D-CES.html#what-we-assume-when-we-synthesize-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>2.4</b> What We Assume When We Synthesize Design-Comparable Effect Sizes</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="D-CES.html"><a href="D-CES.html#what-we-assume-when-we-estimate-design-comparable-effect-size"><i class="fa fa-check"></i><b>2.4.1</b> What We Assume When We Estimate Design-Comparable Effect Size</a></li>
<li class="chapter" data-level="2.4.2" data-path="D-CES.html"><a href="D-CES.html#normality"><i class="fa fa-check"></i><b>2.4.2</b> Normality</a></li>
<li class="chapter" data-level="2.4.3" data-path="D-CES.html"><a href="D-CES.html#homogeneity-of-variance"><i class="fa fa-check"></i><b>2.4.3</b> Homogeneity of Variance</a></li>
<li class="chapter" data-level="2.4.4" data-path="D-CES.html"><a href="D-CES.html#appropriate-structural-model"><i class="fa fa-check"></i><b>2.4.4</b> Appropriate Structural Model</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="D-CES.html"><a href="D-CES.html#modeling-options-for-design-comparable-effect-size-estimation"><i class="fa fa-check"></i><b>2.5</b> Modeling Options for Design-comparable Effect Size Estimation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html"><i class="fa fa-check"></i><b>3</b> Illustration of Design-Comparable Effect Sizes When No Trends Are Assumed</a>
<ul>
<li class="chapter" data-level="3.1" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies"><i class="fa fa-check"></i><b>3.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="3.2" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#details-of-the-no-trend-models-for-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>3.2</b> Details of the No Trend Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="3.3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies"><i class="fa fa-check"></i><b>3.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-1-multiple-baseline-study-by-case1992improving"><i class="fa fa-check"></i><b>3.3.1</b> Example 1: Multiple Baseline Study by <span class="citation">Case et al. (1992)</span></a></li>
<li class="chapter" data-level="3.3.2" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-2-multiple-baseline-study-by-peltier2020effects"><i class="fa fa-check"></i><b>3.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Peltier et al. (2020)</span></a></li>
<li class="chapter" data-level="3.3.3" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#example-3-replicated-abab-design-by-lambert2006effects"><i class="fa fa-check"></i><b>3.3.3</b> Example 3: Replicated ABAB Design by <span class="citation">Lambert et al. (2006)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#estimating-the-design-comparable-effect-size-for-the-group-studies"><i class="fa fa-check"></i><b>3.4</b> Estimating the Design-Comparable Effect Size for the Group Studies</a></li>
<li class="chapter" data-level="3.5" data-path="illustrate-D-CES.html"><a href="illustrate-D-CES.html#analyzing-the-effect-sizes"><i class="fa fa-check"></i><b>3.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html"><i class="fa fa-check"></i><b>4</b> Illustration of Design-Comparable Effect Sizes When Assuming Only Trends in The Treatment Phases</a>
<ul>
<li class="chapter" data-level="4.1" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies-1"><i class="fa fa-check"></i><b>4.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="4.2" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#details-of-the-models-for-design-comparable-effect-sizes"><i class="fa fa-check"></i><b>4.2</b> Details of the Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="4.3" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies-1"><i class="fa fa-check"></i><b>4.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#example-1-multiple-baselise-study-by-gunning2003psychological"><i class="fa fa-check"></i><b>4.3.1</b> Example 1: Multiple Baselise Study by <span class="citation">Gunning &amp; Espie (2003)</span></a></li>
<li class="chapter" data-level="4.3.2" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#example-2-multiple-baseline-study-by-delemere2018parentimplemented"><i class="fa fa-check"></i><b>4.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Delemere &amp; Dounavi (2018)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#estimating-the-design-comparable-effect-size-for-the-group-studies-1"><i class="fa fa-check"></i><b>4.4</b> Estimating the Design-Comparable Effect Size for the Group Studies</a></li>
<li class="chapter" data-level="4.5" data-path="illustrate-D-CES-Ttrends.html"><a href="illustrate-D-CES-Ttrends.html#analyzing-the-effect-sizes-1"><i class="fa fa-check"></i><b>4.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html"><i class="fa fa-check"></i><b>5</b> Illustration of Design-Comparable Effect Sizes When Assuming Trends in Baseline and Different Trends in Treatment</a>
<ul>
<li class="chapter" data-level="5.1" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#selecting-a-design-comparable-effect-size-for-the-single-case-studies-2"><i class="fa fa-check"></i><b>5.1</b> Selecting a Design-Comparable Effect Size for the Single-Case Studies</a></li>
<li class="chapter" data-level="5.2" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#details-of-the-models-for-design-comparable-effect-sizes-1"><i class="fa fa-check"></i><b>5.2</b> Details of the Models for Design-Comparable Effect Sizes</a></li>
<li class="chapter" data-level="5.3" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#estimating-the-design-comparable-effect-size-for-the-single-case-studies-2"><i class="fa fa-check"></i><b>5.3</b> Estimating the Design-Comparable Effect Size for the Single-Case Studies</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#example-1-multiple-probe-study-by-datchuk2016writing"><i class="fa fa-check"></i><b>5.3.1</b> Example 1: Multiple Probe Study by <span class="citation">Datchuk (2016)</span></a></li>
<li class="chapter" data-level="5.3.2" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#example-2-multiple-baseline-study-by-rodgers2021effects"><i class="fa fa-check"></i><b>5.3.2</b> Example 2: Multiple Baseline Study by <span class="citation">Rodgers et al. (2021)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#estimating-the-design-comparable-effect-size-for-the-group-study"><i class="fa fa-check"></i><b>5.4</b> Estimating the Design-Comparable Effect Size for the Group Study</a></li>
<li class="chapter" data-level="5.5" data-path="illustrate-D-CES-Btrends.html"><a href="illustrate-D-CES-Btrends.html#analyzing-the-effect-sizes-2"><i class="fa fa-check"></i><b>5.5</b> Analyzing the Effect Sizes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html"><i class="fa fa-check"></i><b>6</b> Introduction to Multilevel Modeling of Raw Participant Data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#background-2"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#when-to-use-multilevel-models-of-the-raw-data"><i class="fa fa-check"></i><b>6.2</b> When to Use Multilevel Models of the Raw Data</a></li>
<li class="chapter" data-level="6.3" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#what-we-assume-with-multilevel-models-of-the-raw-data"><i class="fa fa-check"></i><b>6.3</b> What We Assume with Multilevel Models of the Raw Data</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#within-case-model-assumptions"><i class="fa fa-check"></i><b>6.3.1</b> Within-Case Model Assumptions</a></li>
<li class="chapter" data-level="6.3.2" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#case-similarity-assumptions"><i class="fa fa-check"></i><b>6.3.2</b> Case Similarity Assumptions</a></li>
<li class="chapter" data-level="6.3.3" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#study-similarity-assumptions"><i class="fa fa-check"></i><b>6.3.3</b> Study Similarity Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#comparison-to-other-synthesis-approaches"><i class="fa fa-check"></i><b>6.4</b> Comparison to Other Synthesis Approaches</a></li>
<li class="chapter" data-level="6.5" data-path="MLM-raw-data.html"><a href="MLM-raw-data.html#multilevel-modeling-options-for-synthesizing-single-case-research"><i class="fa fa-check"></i><b>6.5</b> Multilevel Modeling Options for Synthesizing Single-Case Research</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html"><i class="fa fa-check"></i><b>7</b> Illustration of Multilevel Modeling When No Trends Are Assumed</a>
<ul>
<li class="chapter" data-level="7.1" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#selecting-a-multilevel-model-for-the-single-case-studies"><i class="fa fa-check"></i><b>7.1</b> Selecting a Multilevel Model for the Single-Case Studies</a></li>
<li class="chapter" data-level="7.2" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#details-of-the-no-trend-multilevel-model"><i class="fa fa-check"></i><b>7.2</b> Details of the No-Trend Multilevel Model</a></li>
<li class="chapter" data-level="7.3" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#estimating-a-multilevel-model-for-the-behavior-specific-praise-studies"><i class="fa fa-check"></i><b>7.3</b> Estimating a Multilevel Model for the Behavior Specific Praise Studies</a></li>
<li class="chapter" data-level="7.4" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#appendix"><i class="fa fa-check"></i><b>7.4</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#sas-code"><i class="fa fa-check"></i><b>7.4.1</b> SAS Code</a></li>
<li class="chapter" data-level="7.4.2" data-path="MLM-NoTrend.html"><a href="MLM-NoTrend.html#r-code"><i class="fa fa-check"></i><b>7.4.2</b> R Code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="MLM-Trend.html"><a href="MLM-Trend.html"><i class="fa fa-check"></i><b>8</b> Illustration of Multilevel Modeling When No Trends Are Assumed</a>
<ul>
<li class="chapter" data-level="8.1" data-path="MLM-Trend.html"><a href="MLM-Trend.html#selecting-a-multilevel-model-for-the-single-case-studies-1"><i class="fa fa-check"></i><b>8.1</b> Selecting a Multilevel Model for the Single-Case Studies</a></li>
<li class="chapter" data-level="8.2" data-path="MLM-Trend.html"><a href="MLM-Trend.html#details-of-the-multilevel-model-with-trends"><i class="fa fa-check"></i><b>8.2</b> Details of the Multilevel Model with Trends</a></li>
<li class="chapter" data-level="8.3" data-path="MLM-Trend.html"><a href="MLM-Trend.html#estimating-the-multilevel-model-for-the-included-writing-intervention-studies"><i class="fa fa-check"></i><b>8.3</b> Estimating the Multilevel Model for the Included Writing Intervention Studies</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html"><i class="fa fa-check"></i><b>9</b> Introduction to Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="9.1" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#background-3"><i class="fa fa-check"></i><b>9.1</b> Background</a></li>
<li class="chapter" data-level="9.2" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#when-to-use-case-specific-effect-sizes"><i class="fa fa-check"></i><b>9.2</b> When to Use Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="9.3" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-case-specific-effect-sizes"><i class="fa fa-check"></i><b>9.3</b> Assumptions and Limitations of Case-Specific Effect Sizes</a></li>
<li class="chapter" data-level="9.4" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-nonoverlap-indices"><i class="fa fa-check"></i><b>9.4</b> Assumptions and Limitations of Nonoverlap Indices</a></li>
<li class="chapter" data-level="9.5" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-standardized-mean-differences"><i class="fa fa-check"></i><b>9.5</b> Assumptions and Limitations of Standardized Mean Differences</a></li>
<li class="chapter" data-level="9.6" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-percentage-change-indices-and-log-response-ratios"><i class="fa fa-check"></i><b>9.6</b> Assumptions and Limitations of Percentage Change Indices and Log Response Ratios</a></li>
<li class="chapter" data-level="9.7" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#assumptions-and-limitations-of-percent-of-goal-obtained"><i class="fa fa-check"></i><b>9.7</b> Assumptions and Limitations of Percent of Goal Obtained</a></li>
<li class="chapter" data-level="9.8" data-path="intro-case-specific-es.html"><a href="intro-case-specific-es.html#case-specific-effect-size-options-for-synthesizing-single-case-research"><i class="fa fa-check"></i><b>9.8</b> Case-Specific Effect Size Options for Synthesizing Single-Case Research</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html"><i class="fa fa-check"></i><b>10</b> Application of Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="10.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#selecting-case-specific-effect-sizes-for-the-single-case-studies"><i class="fa fa-check"></i><b>10.1</b> Selecting Case-Specific Effect Sizes for the Single-Case Studies</a></li>
<li class="chapter" data-level="10.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#estimating-the-case-specific-effect-sizes-for-the-included-aac-intervention-studies"><i class="fa fa-check"></i><b>10.2</b> Estimating the Case-Specific Effect Sizes for the Included AAC Intervention Studies</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#entering-the-data-into-excel"><i class="fa fa-check"></i><b>10.2.1</b> Entering the Data into Excel</a></li>
<li class="chapter" data-level="10.2.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#accessing-the-app"><i class="fa fa-check"></i><b>10.2.2</b> Accessing the App</a></li>
<li class="chapter" data-level="10.2.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#loading-the-data-into-the-app"><i class="fa fa-check"></i><b>10.2.3</b> Loading the Data into the App</a></li>
<li class="chapter" data-level="10.2.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#defining-the-variable-within-the-app"><i class="fa fa-check"></i><b>10.2.4</b> Defining the Variable within the App</a></li>
<li class="chapter" data-level="10.2.5" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#examining-the-graphs-within-the-app"><i class="fa fa-check"></i><b>10.2.5</b> Examining the Graphs within the App</a></li>
<li class="chapter" data-level="10.2.6" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#estimating-the-effect-sizes-within-the-app"><i class="fa fa-check"></i><b>10.2.6</b> Estimating the Effect Sizes within the App</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#syntex-for-r"><i class="fa fa-check"></i><b>10.3</b> Syntex for R</a></li>
<li class="chapter" data-level="10.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#examining-the-alignment-of-the-case-specific-effect-sizes-with-our-visual-analysis"><i class="fa fa-check"></i><b>10.4</b> Examining the Alignment of the Case-Specific Effect Sizes with our Visual Analysis</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#nap"><i class="fa fa-check"></i><b>10.4.1</b> NAP</a></li>
<li class="chapter" data-level="10.4.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#smd-results"><i class="fa fa-check"></i><b>10.4.2</b> SMD Results</a></li>
<li class="chapter" data-level="10.4.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#lrri-results"><i class="fa fa-check"></i><b>10.4.3</b> LRRi Results</a></li>
<li class="chapter" data-level="10.4.4" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#pogomuparrow"><i class="fa fa-check"></i><b>10.4.4</b> PoGO<sub>M<span class="math inline">\(\uparrow\)</span></sub></a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#averaging-the-case-specific-effect-sizes"><i class="fa fa-check"></i><b>10.5</b> Averaging the Case-Specific Effect Sizes</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#fixed-effects-meta-analysis"><i class="fa fa-check"></i><b>10.5.1</b> Fixed Effects Meta-Analysis</a></li>
<li class="chapter" data-level="10.5.2" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#random-effects-meta-analysis"><i class="fa fa-check"></i><b>10.5.2</b> Random Effects Meta-Analysis</a></li>
<li class="chapter" data-level="10.5.3" data-path="app-case-specific-es.html"><a href="app-case-specific-es.html#further-directions-for-synthesizing-case-specific-effect-sizes"><i class="fa fa-check"></i><b>10.5.3</b> Further Directions for Synthesizing Case-Specific Effect Sizes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methods Guide for Effect Estimation and Synthesis of Single-Case Studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="MLM-Trend" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Illustration of Multilevel Modeling When No Trends Are Assumed<a href="MLM-Trend.html#MLM-Trend" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>This chapter demonstrates the application of multilevel models that include time trends in the baseline and/or treatment phases. For illustrative purposes, we use data from four single-case studies examining interventions for improving student writing. We provide step-by-step instructions to demonstrate organization of the data, necessary coding of variables, appropriate multilevel model selection, and model specification and estimation using the MultiSCED app.</em></p>
<p>In this chapter, we illustrate the application of multilevel modeling in contexts where one expects single-case design (SCD) study data to include time trends. Just as in the previous chapter, the approach presented in this chapter assumes that all included SCD studies measured the dependent variable in the same way, or in ways that can be standardized so that the outcomes and measures of time are operationalized using a common scale. Unique to this chapter, we demonstrate the specification and analysis process for a model in which the dependent variable is expected to systematically increase or decrease during a phase, and the intervention is expected to impact the outcome’s level and rate of change over time. As a running example, we imagine a scenario where our goal is to synthesize evidence from SCDs studies that examine intervention effects on writing outcomes—specifically on students’ rate of correct word sequences written per minute.</p>
<p>Writing interventions are often necessary when students’ writing skill lags behind their peers. Due to natural school-based instructional activities, we anticipate that some students may show slight improvement during baseline. However, only when the struggling writers begin intervention do we expect an immediate increase in the production of correct word sequences, and an increase in their rate of improvement over time. To illustrate the steps for applying multilevel models in contexts where trends are expected, we use a set of four multiple probe and multiple baseline SCDs previously included in a larger review of intervention effects on student writing outcomes <span class="citation">(<a href="#ref-datchuk2020Level">Datchuk et al., 2020</a>)</span>. In a real, full-scale meta-analysis project, we would synthesize all studies meeting the inclusion criteria. However, our illustrations include only four studies from the larger review to succinctly illustrate the details of the modeling process that includes visually analyzing the data of each primary study for consistency with our expectations and with the assumptions of the selected multilevel model.</p>
<p>In two multiple probe studies, <span class="citation">B. Walker et al. (<a href="#ref-walker2005using">2005</a>)</span> and <span class="citation">B. D. Walker et al. (<a href="#ref-walker2007improving">2007</a>)</span>, researchers examined the impact of a rule-based direct instruction intervention on the expressive writing of high schoolers with learning disabilities. In our third study, <span class="citation">Stotz et al. (<a href="#ref-stotz2008Effects">2008</a>)</span> investigated the effects of a self-graphing intervention using a multiple baseline design across three fourth graders with high-incidence disabilities. In the fourth study, <span class="citation">Lewandowski (<a href="#ref-lewandowski2011effects">2011</a>)</span> examined the effects of a planning and drafting intervention on writing using a multiple baseline design across six elementary students with attention difficulties. While this final study included two participants with only two baseline observations, we include it here for the purposes of our illustration. However, for other purposes, researchers might choose to exclude the <span class="citation">Lewandowski (<a href="#ref-lewandowski2011effects">2011</a>)</span> study because its design does not meet the <em>What Works Clearinghouse Standards</em> <span class="citation">(<a href="#ref-WWC2022">2020a</a>)</span> for multiple baseline designs.</p>
<p>In this chapter illustration, our goal is to model the outcome data from all cases in all studies to estimate the average effect of writing interventions on the rate of writing correct word sequences. This objective is feasible because each of the studies measures the number of correct word sequences written by students. To analyze these outcomes on a common scale, we convert all data to correct word sequences per minute.</p>
<p>Because our model includes trends, we must make two important decisions about the most appropriate method for operationally defining a common time variable. First, to determine the unit of time measurement, we consider how the outcome we are trying to measure changes over time. For instance, changes could occur linearly across calendar days, across school days, or across intervention sessions (which might occur more or less frequently than once per school day). If we anticipate changes occurring during baseline due to maturation, the calendar day unit of measurement might be appropriate. If we anticipate baseline change to occur related to regular teaching and learning activities in the classroom, it may be best to measure the outcome using the unit of school days. Alternatively, if we expect changes to occur with each additional intervention session, then perhaps session number is the ideal choice for the units of time.</p>
<p>Next, when primary studies use different units to measure time, meta-analysts must convert raw data to use a consistent unit for time in the analysis. In three of our four included studies, the authors reported “sessions” as the only unit of time (the exception was <span class="citation">Stotz et al. (<a href="#ref-stotz2008Effects">2008</a>)</span>, who measured the outcome across consecutive school days). Although less ideal than a more precise time specification (e.g., days), our operationalization of time to model trends is limited the use of “sessions” because no other information was available within the <span class="citation">Lewandowski (<a href="#ref-lewandowski2011effects">2011</a>)</span> or Walker <span class="citation">(<a href="#ref-walker2005using">2005</a>; <a href="#ref-walker2007improving">2007</a>)</span> manuscripts. While we acknowledge the potential biases in estimating effects with a less precise definition of time, we find it reasonable to use “sessions” as the unit of time because we expect writing to improve with practice, and writing practice is largely expected to occur within the observation sessions. We recommend meta-analysts in a similar situation provide rationales for their selection of a common time variable so these limitations can be taken into consideration when reviewing the effect estimation results.</p>
<p>After operationalizing our outcome measure and time variables, we proceed with the selection of a multilevel modeling approach in effect estimation because we are interested in how intervention impacts both the level and slope of students’ writing over time (see the decision rules in Figure 1.1). Thus, we divide this chapter illustration into two stages: (a) selecting a multilevel model for the studies and (b) estimating the multilevel model using the MultiSCED app, a web-based application for conducting multilevel models of SCD studies <span class="citation">(<a href="#ref-Declercq2020">Declercq et al., 2020</a>)</span>.</p>
<div id="selecting-a-multilevel-model-for-the-single-case-studies-1" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Selecting a Multilevel Model for the Single-Case Studies<a href="MLM-Trend.html#selecting-a-multilevel-model-for-the-single-case-studies-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Using the decision rules in Figure <a href="MLM-raw-data.html#fig:mlmapproach">6.2</a>, we first select among the general multilevel modeling approaches. We must decide whether we should treat the outcome as a continuous variable that is normally distributed around the trend lines. The common study outcome is a rate of correct writing sequences per minute, which is based on a count. Thus, it would be reasonable to consider a generalized linear mixed model (GLMM) that does not assume normality. However, GLMMs are more complex than linear mixed models (LMMs) and there is limited evidence of GLMM utility for synthesizing SCDs. For the purposes of this methods guide, we will examine our expectations about the outcome for the contexts studied. In addition, we will visually analyze the graphed outcome data over time per case to gauge the potential severity of any violation to the normality assumption. If not too severe, we will proceed with LMMs because there is evidence of their ability to produce unbiased estimates of treatment effects quantified as average mean differences or mean changes in linear slope on the scale of the outcome, along with appropriate inferences, even in contexts where outcomes are not normally distributed <span class="citation">(<a href="#ref-Declercq2019">Declercq et al., 2019</a>; <a href="#ref-Joo_Ferron_2019">Joo &amp; Ferron, 2019</a>)</span>. In the future, we anticipate that further methodological research will better clarify the relative merits of GLMMs versus LMMs and provide clearer guidance for researchers to select among the options.</p>
<p>In this illustration, the outcome is students’ rate of correct word sequences written per minute. Given our prior knowledge and experience with this dependent variable, we anticipate that outcome levels will be lower than desirable in baseline, but not at the floor. That is, we do not expect participants’ baselines to solely contain observations with values of zero. Following intervention, we predict the rates of correctly written word sequences to be further from zero and to more closely approximate a normal distribution.</p>
<p>We present the included study graphs in Figure <a href="MLM-Trend.html#fig:Walker-2005">8.1</a> <span class="citation">(<a href="#ref-walker2005using">B. Walker et al., 2005</a>)</span>, Figure <a href="MLM-Trend.html#fig:Walker-2007">8.2</a> <span class="citation">(<a href="#ref-walker2007improving">B. D. Walker et al., 2007</a>)</span>, Figure <a href="MLM-Trend.html#fig:Stotz-2008">8.3</a> <span class="citation">(<a href="#ref-stotz2008Effects">Stotz et al., 2008</a>)</span>, and Figure <a href="MLM-Trend.html#fig:Lewandowski-2011">8.4</a> <span class="citation">(<a href="#ref-lewandowski2011effects">Lewandowski, 2011</a>)</span>. For each of these studies, we visually inspect the graphs to rule out obvious non-normality (i.e., constant values within a phase, or trend lines so close to the floor or ceiling that variation on one side of the trend line is notably different than on the other side). Visual analysis of the graphed data in Figures <a href="MLM-Trend.html#fig:Walker-2005">8.1</a>-<a href="MLM-Trend.html#fig:Lewandowski-2011">8.4</a> suggest variation around the trend lines that are not obviously non-normal. To better understand the potential degree of a normality assumption violation, we pooled the deviations from the ordinary least squares estimates of within-phase trend lines for each case included in the studies and estimated the skew and kurtosis of the distribution of the deviations. Resulting summary indices suggest moderate departures from normality in baseline (<span class="math inline">\(sk = 1.56\)</span>; <span class="math inline">\(ku = 7.43\)</span>), and a closer-to-normal distribution in the treatment phase (<span class="math inline">\(sk = 0.11\)</span>; <span class="math inline">\(ku = 4.79\)</span>). Because the distributions are not severely non-normal and research suggests that LMMs for SCD data can handle some non-normality in the outcomes <span class="citation">(<a href="#ref-Declercq2019">Declercq et al., 2019</a>; <a href="#ref-Joo_Ferron_2019">Joo &amp; Ferron, 2019</a>)</span>, we proceed with use of an LMM, which also allows us to illustrate the MultiSCED app.</p>
<div class="figure"><span style="display:block;" id="fig:Walker-2005"></span>
<img src="images/Walker2005.png" alt="Effect of Intervention on Correct Word Sequences (Walker et al., 2005)" width="60%" />
<p class="caption">
Figure 8.1: Effect of Intervention on Correct Word Sequences (Walker et al., 2005)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Walker-2007"></span>
<img src="images/Walker2007.png" alt="Effect of Intervention on Correct Word Sequences (Walker et al., 2007)" width="60%" />
<p class="caption">
Figure 8.2: Effect of Intervention on Correct Word Sequences (Walker et al., 2007)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Stotz-2008"></span>
<img src="images/Stotz2008.png" alt="Effect of Intervention on Correct Word Sequences (Stotz et al., 2008)" width="60%" />
<p class="caption">
Figure 8.3: Effect of Intervention on Correct Word Sequences (Stotz et al., 2008)
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:Lewandowski-2011"></span>
<img src="images/Lewandowski2011.png" alt="Effect of Intervention on Correct Word Sequences (Lewandowski, 2011)" width="60%" />
<p class="caption">
Figure 8.4: Effect of Intervention on Correct Word Sequences (Lewandowski, 2011)
</p>
</div>
<p>Next, we must decide whether to include trends in our model. The outcome in each study is the rate of writing correct word sequences. Using prior knowledge of this academic outcome and the context of the studies, it is plausible that some participants show a slight degree of improvement in the writing outcome during the baseline phase because students engage in writing activities in a variety of academic contexts. However, we do not anticipate a general positive linear trend to be present across all cases in all studies. Unlike our expectations for baseline data, we are more confident in our assumption that the interventions will result not only in an immediate and noticeable increase in students’ correctly written word sequences, but also in a change in the rate of growth. Therefore, we plan to model trends in the treatment phases.</p>
<p>Visual inspections of the graphs in Figures <a href="MLM-Trend.html#fig:Walker-2005">8.1</a>-<a href="MLM-Trend.html#fig:Lewandowski-2011">8.4</a> are partially consistent with our expectations for baseline and treatment phase trends. Overall, we do not see a consistent pattern in trends for participants’ baseline writing rates. Turning to the treatment phases, visual inspection of participants’ graphs across studies reveals a general positive linear trend in the data as expected. For most cases, the treatment phase trends appear steeper than any trends present in the baseline phase, but the pattern of positive trends across the cases is not consistent. There is also variability in intervention duration (i.e., treatment phase length). However, based on our understanding of the study outcome (i.e., writing) and context (i.e., school setting), and consistent trends during intervention across most cases (especially in Figures <a href="MLM-Trend.html#fig:Walker-2005">8.1</a> and <a href="MLM-Trend.html#fig:Walker-2007">8.2</a>), it appears reasonable to use a multilevel model with trends (at least in the treatment phases).</p>
<p>We turn next to an examination of the within-case variance using visual analysis of study graphs. Figures <a href="MLM-Trend.html#fig:Walker-2005">8.1</a>-<a href="MLM-Trend.html#fig:Lewandowski-2011">8.4</a> show similar variation across baseline and treatment phases and a follow-up statistical analysis of the deviations from trend lines shows that the standard deviation (SD) of these deviations was 1.35 in baseline and 1.53 in intervention. Although the within-case variability is similar across phases, it appears to differ across studies, with more variability in the latter two studies that examined younger children. Adding confidence to this conclusion, descriptive statistics for the Walker et al. <span class="citation">B. D. Walker et al. (<a href="#ref-walker2007improving">2007</a>)</span> studies indicate deviations from the trend lines of 0.46 and 0.50 SDs respectively, whereas the SDs from the trend lines for the studies by <span class="citation">Stotz et al. (<a href="#ref-stotz2008Effects">2008</a>)</span> and <span class="citation">Lewandowski (<a href="#ref-lewandowski2011effects">2011</a>)</span> are 2.32 and 2.46 respectively. This obvious violation of the homogeneity assumption appears to be at least partially responsible for the high kurtosis values seen in our examination of normality. Examining normality within each study, the maximum kurtosis value is only 1.5 (for <span class="citation">B. Walker et al. (<a href="#ref-walker2005using">2005</a>)</span>). While it is feasible to estimate separate covariance matrices for the studies with older and younger participants <span class="citation">(<a href="#ref-baek2016using">E. K. Baek et al., 2016</a>; <a href="#ref-baek_Ferron_2020">E. Baek &amp; Ferron, 2020</a>)</span>, these more complex heterogeneous variance models are not accessible via the MultiSCED app. In addition, the average treatment effect size estimates (changes in level and slope) and related inferences are relatively robust to this sort of violation of the homogeneity assumption <span class="citation">(<a href="#ref-baek_Ferron_2020">E. Baek &amp; Ferron, 2020</a>)</span>, so proceeding with the simpler homogeneous variance models seems reasonable.</p>
<p>In summary, our visual analyses of the primary study data resulted in several conflicts between our expectations, the study results, and the assumptions associated with a multilevel model with trends. First, the inconsistencies raise questions about whether we need to include baseline trends in our model specification. Second, there are multiple violations to the assumptions of the basic LMM for SCD studies, like evidence of non-normality (particularly in the baseline phases) and heterogeneity of variance across cases. The model we use in this chapter is surely simpler than the process that actually generated the data under analysis. With a relatively small number of studies, one may want to further simplify their model specification by removing baseline trends. However, for purposes of illustrating multilevel modeling of trends using the MultiSCED app, we proceed with the more elaborate model specification. We also note that the multilevel model estimates of the across-case average treatment effects (i.e., change in level, change in trend), as well as the inferences associated with those effects (e.g., confidence intervals, significance tests), are relatively robust to violations of the normality and homogeneity assumptions.</p>
</div>
<div id="details-of-the-multilevel-model-with-trends" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Details of the Multilevel Model with Trends<a href="MLM-Trend.html#details-of-the-multilevel-model-with-trends" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The multilevel data structure has repeated observations that are nested within cases and cases that are nested within studies, and thus there is a model for the variation of observations within a case (level-1), a model for the variation between cases within a study (level-2), and a model for variation between studies (level-3). The formal specification of the within-case (level-1) model with trends in both the baseline phase and the treatment phase is:
<span class="math display" id="eq:MLM-L1-Trend">\[\begin{equation}
\tag{8.1}
Y_{ijk} = \beta_{0jk} + \beta_{1jk}Tx_{ijk} + \beta_{2jk}Time_{ijk} + \beta_{3jk}Tx_{ijk} \times Time_{ijk} + e_{ijk},
\end{equation}\]</span>
where <span class="math inline">\(Y_{ijk}\)</span> is the outcome variable <span class="math inline">\(Y\)</span> at measurement occasion <span class="math inline">\(i\)</span> for case <span class="math inline">\(j\)</span> of study <span class="math inline">\(k\)</span>. Tx_{ijk} is dummy coded with a value of 0 for baseline phase observations and a value of 1 for treatment phase observations. <span class="math inline">\(Time_{ijk}\)</span> is the value of the time variable on occasion <span class="math inline">\(i\)</span> for case <span class="math inline">\(j\)</span> of study <span class="math inline">\(k\)</span>. The error term, <span class="math inline">\(e_{ijk}\)</span>, is time-, case-, and study-specific, and assumed independently and normally distributed with variance <span class="math inline">\(\sigma_e^2\)</span>. Outside of the MultiSCED app, it is feasible for researchers to estimate a different (co)variance structure for <span class="math inline">\(e_{ijk}\)</span>, such as first-order autoregressive or heterogeneous across phases or cases <span class="citation">(<a href="#ref-baek2016using">E. K. Baek et al., 2016</a>; <a href="#ref-Joo_et_al_2019">Joo et al., 2019</a>; <a href="#ref-Petit-Bois_2014">Petit-Bois, 2014</a>)</span>.</p>
<p>Second, we must decide how to center the <span class="math inline">\(Time_{ijk}\)</span> variable (i.e., at what point in time is the value of <span class="math inline">\(Time_{ijk}\)</span> equal to zero). Our choice of the focal time to index the effect has consequences for how we interpret the regression coefficients of the model. The most common choice is to code <span class="math inline">\(Time_{ijk}\)</span> such that zero (0) corresponds to the first treatment phase observation for case <span class="math inline">\(j\)</span> for study <span class="math inline">\(k\)</span>. Because this centering choice is appropriate for this example, and because the MultiSCED app will do this centering of time for us, we do not need to enter the centered time variable into our dataset. If we wanted to enter this centered time variable during our data organization phase, we would code the treatment phase observations sequentially starting from 0 (i.e., 1 for the second treatment phase observation, 2 for the third, and so on). For baseline phase observations, coding begins by working back from 0. In other words, we would code the last baseline phase observation as -1, the second-to-last baseline observation as -2, and so on.</p>
<p>Then, after deciding to center <span class="math inline">\(Time_{ijk}\)</span> such that 0 corresponds to the first treatment observation, we can interpret <span class="math inline">\(\beta_{0jk}\)</span> as the expected baseline value for case <span class="math inline">\(j\)</span> of study <span class="math inline">\(k\)</span> if the baseline is extended to the first treatment observation. <span class="math inline">\(\beta_{1jk}\)</span> is then interpreted as the immediate effect of the intervention (i.e., the difference between the treatment phase trend line and the extended baseline trend line at time zero). Figure <a href="MLM-Trend.html#fig:Walker-Darren">8.5</a> visually depicts these regression coefficients. The baseline slope is <span class="math inline">\(\beta_{2jk}\)</span>, and the change in slope between baseline and treatment phases is <span class="math inline">\(\beta_{3jk}\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:Walker-Darren"></span>
<img src="images/Walker2005_Darren.png" alt="Illustration of Treatment Effect for Darren (Walker et al., 2005)" width="60%" />
<p class="caption">
Figure 8.5: Illustration of Treatment Effect for Darren (Walker et al., 2005)
</p>
</div>
<p>The between-case (level-2) model is:
<span class="math display" id="eq:MLM-L2-beta0">\[\begin{equation}
\tag{8.2}
\beta_{0jk} = \gamma_{00k} + u_{0jk}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L2-beta1">\[\begin{equation}
\tag{8.3}
\beta_{1jk} = \gamma_{10k} + u_{1jk}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L2-beta2">\[\begin{equation}
\tag{8.4}
\beta_{2jk} = \gamma_{20k} + u_{2jk}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L2-beta3">\[\begin{equation}
\tag{8.5}
\beta_{3jk} = \gamma_{30k} + u_{3jk}
\end{equation}\]</span>
where <span class="math inline">\(\gamma_{00k}\)</span> is the expected across-case average baseline value at the time of the first treatment observation of study <span class="math inline">\(k\)</span>, <span class="math inline">\(\gamma_{10k}\)</span> is the across-case average immediate treatment effect of study <span class="math inline">\(k\)</span>, <span class="math inline">\(\gamma_{20k}\)</span> is the across-case average baseline slope, and <span class="math inline">\(\gamma_{30k}\)</span> is the across-case average change in slope between baseline and treatment phases. The case-specific errors (<span class="math inline">\(u_{0jk}\)</span>, <span class="math inline">\(u_{1jk}\)</span>, <span class="math inline">\(u_{2jk}\)</span>, and <span class="math inline">\(u_{3jk}\)</span>) correspond to the regression coefficient deviations of individual case <span class="math inline">\(j\)</span> of study <span class="math inline">\(k\)</span> from the across-case average values for study <span class="math inline">\(k\)</span>. These case-specific errors are assumed multivariate normal with covariance
<span class="math inline">\(\Sigma_u = \begin{bmatrix} \sigma_{u_0}^2 &amp; &amp; &amp; \\ \sigma_{u_1u_0} &amp; \sigma_{u_1}^2 &amp; &amp; \\ \sigma_{u_2u_0} &amp; \sigma_{u_2u_1} &amp; \sigma_{u_2}^2 &amp; \\ \sigma_{u_3u_0} &amp; \sigma_{u_3u_1} &amp; \sigma_{u_3u_2} &amp; \sigma_{u_3}^2\\ \end{bmatrix}\)</span>.
In some applications, an unstructured matrix will be difficult to estimate with the limited number of cases available. Common alternatives include estimating a diagonal covariance structure or removing errors from Equations <a href="MLM-Trend.html#eq:MLM-L2-beta2">(8.4)</a> and <a href="MLM-Trend.html#eq:MLM-L2-beta3">(8.5)</a> so that some of the slopes do not vary randomly across cases.</p>
<p>The between-study (level-3) model is:
<span class="math display" id="eq:MLM-L3-beta0">\[\begin{equation}
\tag{8.6}
\gamma_{00k} = \theta_{000} + v_{00k}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L3-beta1">\[\begin{equation}
\tag{8.7}
\gamma_{10k} = \theta_{100} + v_{10k}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L3-beta2">\[\begin{equation}
\tag{8.8}
\gamma_{20k} = \theta_{200} + v_{20k}
\end{equation}\]</span>
<span class="math display" id="eq:MLM-L3-beta3">\[\begin{equation}
\tag{8.9}
\gamma_{30k} = \theta_{300} + v_{30k}
\end{equation}\]</span>
where <span class="math inline">\(\theta_{000}\)</span> is the across-study average expected baseline value at the time of the first treatment observation, <span class="math inline">\(\theta_{100}\)</span> is the across-study average immediate treatment effect, <span class="math inline">\(\theta_{200}\)</span> is the-across study average baseline slope, and <span class="math inline">\(\theta_{300}\)</span> is the across-study average change in slope between baseline and treatment phases. The study-specific errors (<span class="math inline">\(v_{00k}\)</span>, <span class="math inline">\(v_{10k}\)</span>, <span class="math inline">\(v_{20k}\)</span>, and <span class="math inline">\(v_{30k}\)</span>) correspond to the deviations of the across-case average coefficient values of study <span class="math inline">\(k\)</span> from the overall values averaged across all studies. These study-specific errors are assumed multivariate normal with covariance
<span class="math inline">\(\Sigma_v = \begin{bmatrix} \sigma_{v_0}^2 &amp; &amp; &amp; \\ \sigma_{v_1v_0} &amp; \sigma_{v_1}^2 &amp; &amp; \\ \sigma_{v_2v_0} &amp; \sigma_{v_2v_1} &amp; \sigma_{v_2}^2 &amp; \\ \sigma_{v_3v_0} &amp; \sigma_{v_3v_1} &amp; \sigma_{v_3v_2} &amp; \sigma_{v_3}^2\\ \end{bmatrix}\)</span>. In many applications, an unstructured matrix will be difficult to estimate with the limited number of studies available. In our example, the data include only four independent studies, which would not be considered adequate for estimating an unstructured covariance matrix. Common alternatives include estimating a diagonal covariance structure or removing errors from some of Equations <a href="MLM-Trend.html#eq:MLM-L3-beta2">(8.8)</a> and <a href="MLM-Trend.html#eq:MLM-L3-beta3">(8.9)</a> (and potentially <a href="MLM-Trend.html#eq:MLM-L3-beta1">(8.7)</a>) so these regression coefficients do not vary randomly across the studies.</p>
<p>For the purposes of the methods guide, we illustrate in detail the estimation of the multilevel model for the writing outcome of correct word sequences per minute using the MultiSCED app <span class="citation">(<a href="#ref-Declercq2020">Declercq et al., 2020</a>)</span>. This app limits users to LMMs and the covariance structures described in this section. To allow for the exploration of how model specification details influence estimates and inferences, we contrast the full model results (from Equations <a href="MLM-Trend.html#eq:MLM-L1-Trend">(8.1)</a> to <a href="MLM-Trend.html#eq:MLM-L3-beta3">(8.9)</a>) with models having simpler covariance structures (e.g., models without as many coefficients varying randomly across studies). See Chapter 7 Appendix for examples of SAS and R code used to estimate models with diagonal covariance structures.</p>
</div>
<div id="estimating-the-multilevel-model-for-the-included-writing-intervention-studies" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Estimating the Multilevel Model for the Included Writing Intervention Studies<a href="MLM-Trend.html#estimating-the-multilevel-model-for-the-included-writing-intervention-studies" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Using the web-based MultiSCED calculator for the multilevel modeling of single-case data, we can estimate the across-case average treatment effect and variance components describing the degree of heterogeneity in treatment effects. The MultiSCED app is available at <a href="http://34.251.13.245/MultiSCED/" class="uri">http://34.251.13.245/MultiSCED/</a>. To use this app, researchers must save their dataset as a text file (.txt) or a comma-delimited file (.csv). We recommend that researchers first enter their data in Excel, and then save the Excel dataset as a tab-delimited text file.</p>
<p>Figure <a href="MLM-Trend.html#fig:Excel-Lewandowski">8.6</a> shows a screenshot of a portion of the original Excel spreadsheet containing the data extracted from the set of four writing intervention studies, with correct word sequence writing outcomes converted as needed to compare rates on a common per-minute scale. This spreadsheet contains six columns of data corresponding to the following six variables: (a) study identifier (i.e., Study), (b) case identifier (i.e., ID), (c) point in time for which the outcome was recorded (i.e., Time), (d) frequency outcome (number of correct word sequences written; i.e., CWS), (e) rate outcome (rate of correct word sequences written per minute, CWSpM), and (f) phase identifier (i.e., intervention). Note that the time variable is numbered sequentially from first observation to last observation and has not yet been centered relative to the start of the treatment phase.</p>
<p>To use the MultiSCED app, the session and outcome variables must be numerical values. However, the variables for study, case, and phase identifiers may be entered as alphanumeric (word labels) or numeric values. Because the app requires it, we organized the data using a long format with one row per time point per case per study, where we input the value of the outcome at each time point for a specific case below the cell containing the value at the previous time point. For each study (e.g., Lewandowski in Figure <a href="MLM-Trend.html#fig:Excel-Lewandowski">8.6</a>), we first arranged cases by baseline length. In order of shortest to longest baseline length, we entered all observations for one case at a time, in order of time. After we entered all data for the case with the shortest baseline, we entered data for the case with the second-shortest baseline, and so on. After entering the data for all cases within a particular study, we repeated the process with the remaining studies; we entered the data from each successive study below the data from the previous study.</p>
<div class="figure"><span style="display:block;" id="fig:Excel-Lewandowski"></span>
<img src="images/excel_Lewandowski2011.png" alt="Screenshot of Extracted Study Data Within the Original Excel Spreadsheet" width="60%" />
<p class="caption">
Figure 8.6: Screenshot of Extracted Study Data Within the Original Excel Spreadsheet
</p>
</div>
<p>After organizing the data within the Excel spreadsheet, we then save the Excel spreadsheet as a tab delimited text file (.txt). We present a screenshot of a portion of the resulting text file in Figure <a href="MLM-Trend.html#fig:Txt-Lewandowski">8.7</a>. To prepare the data set for the MultiSCED app, one can follow the steps below.</p>
<p>For Windows:</p>
<ol style="list-style-type: decimal">
<li>From the <em>File</em> menu, select <em>Save As</em>.</li>
<li>Select <em>Browse</em> to select a folder where the spreadsheet will be saved.</li>
<li>To save the spreadsheet, enter a file name in the corresponding field.</li>
<li>Then use the <em>Save as</em> Type menu to select the option to save the file type as Text (Tab delimited) (*.txt).</li>
<li>Finally, click <em>Save</em>.</li>
</ol>
<p>If there are multiple worksheets within the original Excel spreadsheet file, a pop-up message will appear to request permission to save only the active sheet. If this occurs, select OK to save the data file. We strongly encourage researchers to open the newly created tab delimited text file to ensure that the data appear as expected.</p>
<p>For MacOS:</p>
<ol style="list-style-type: decimal">
<li>From the <em>File</em> menu, select <em>Save As</em>.</li>
<li>Enter a file name in the <em>Save As</em> field.</li>
<li>Select a location from the dropdown menu, <em>Where</em>, to save your spreadsheet.</li>
<li>Then use the <em>File Format</em> menu to select the option to save your file type as Tab delimited Text (.txt).</li>
<li>Finally, click <em>Save</em>.</li>
</ol>
<p>It is important to note here that an error message will appear if attempting to save a spreadsheet with multiple worksheets. A pop-up will inform you that the workbook cannot be saved in the selected file format. If encountering this error, researchers should open a newly created file with one worksheet for the data needed in their analysis.</p>
<div class="figure"><span style="display:block;" id="fig:Txt-Lewandowski"></span>
<img src="images/raw_txt.file_Lewandowski2011.png" alt="Screenshot of Saved Tab Delimited Text File" width="60%" />
<p class="caption">
Figure 8.7: Screenshot of Saved Tab Delimited Text File
</p>
</div>
<p>After converting and saving the dataset as a tab delimited text file, we are prepared to use the MultiSCED app (<a href="http://34.251.13.245/MultiSCED/" class="uri">http://34.251.13.245/MultiSCED/</a>). Figure 8.8 is a screenshot of the Home page for the MultiSCED app. At the top of the page, one will see that the <em>Home</em> link on the blue menu bar has a darker background than the other website page links. To access the app, we must move from the <em>Home</em> page to the <em>Input</em> page by clicking on the Input link in the website navigation menu bar.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-navigation-homepage"></span>
<img src="images/multiSCED.homepage.png" alt="Screenshot of the Website Navigation Menu and Home Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.8: Screenshot of the Website Navigation Menu and Home Page of the MultiSCED App
</p>
</div>
<p>A screenshot of the <em>Input</em> page is shown in Figure <a href="MLM-Trend.html#fig:MultiSCED-input-dataFile">8.9</a>. After navigating to the <em>Input</em> page, we find a sidebar menu with three additional links: <em>Data file</em>, <em>Variables</em>, and <em>Data summary</em>. We first select the sidebar option to choose the <em>Data file</em> section. When it is highlighted in dark blue (as in Figure <a href="MLM-Trend.html#fig:MultiSCED-input-dataFile">8.9</a>), we can upload our dataset (.txt or .csv) by clicking the <em>Browse</em> button, selecting the folder where the data file is saved, and clicking <em>Open</em>. When we did this, two additional menus appeared in the <em>Upload</em> box beneath the <em>Browse</em> button: <em>Separator character</em> and <em>Decimal character</em>. The default option for the <em>Separator character</em> is tab. We keep the default setting because we already saved the dataset as a tab delimited text file. However, if your file is saved as a .csv file, you can select <em>comma</em> under the <em>Separator character</em> dropdown menu. Regarding the <em>Decimal character</em> menu, the option for decimal representation defaults to dot, which is the standard choice in the U.S. However, for researchers located outside of the U.S. that use commas to mark decimals (e.g., EU countries), the setting will need to be changed from the default of dot to the comma option. We note here that researchers can use sample data to practice using the app. To access sample data, researchers should upload any file (which will not be used) and then click on the <em>Use testdata</em> checkbox. Sample data information will be automatically input into the <em>Variables</em> section which follows. After completing these actions, we transition to the <em>Variables</em> section on the left side of the screen.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-input-dataFile"></span>
<img src="images/MultiSCED_input.datafile.png" alt="Screenshot of the Input Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.9: Screenshot of the Input Page of the MultiSCED App
</p>
</div>
<p>As shown in Figure <a href="MLM-Trend.html#fig:MultiSCED-input-variables-Lewandowski">8.10</a> of the MultiSCED app <em>Input</em> page, the <em>Variables</em> section appears as the second option in the left sidebar under <em>Data file</em>. When highlighted in dark blue, the <em>Variables</em> page has two primary sections: <em>Base variables</em> and <em>Moderator variables</em>. Using the drop-down menus in the <em>Base variables</em> section, we select our outcome variable (i.e., CWSpM) from the <em>Response</em> menu, case identifier from the <em>Case</em> menu, study identifier from the <em>Study</em> menu, and phase identifier from the <em>Phase</em> menu. We also use the <em>Phase control group</em> drop-down menu to define our dummy coded values for baseline observations and specify our time variable from the options in the <em>Time</em> drop-down menu. Because we are modeling trends, we also check the box next to <em>Center time variable</em>. The app will center time for each case so that zero corresponds to the first intervention observation allowing the coefficient for <em>Intervention</em> to index the immediate effect of the intervention. Figure <a href="MLM-Trend.html#fig:MultiSCED-input-variables-Lewandowski">8.10</a> shows the <em>Variables</em> tab, along with the appropriate menu selections for this model.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-input-variables-Lewandowski"></span>
<img src="images/MultiSCED_input.variables_Lewandowski2011.png" alt="Screenshot of the Variables Section Within the Input Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.10: Screenshot of the Variables Section Within the Input Page of the MultiSCED App
</p>
</div>
<p>After specifying our variables, we navigate to the <em>Data summary</em> section of the app. We show a screenshot for the <em>Data summary</em> tab in Figure <a href="MLM-Trend.html#fig:MultiSCED-input-datasummary-Lewandowski">8.11</a>. At the top of the page, the app summarizes the data for each of the three levels in our model: the number of studies included (i.e., 4), the number of cases nested within these four studies (i.e., 15 cases), and the total number of observations nested within the cases that are nested within the studies (i.e., 442). These values all correspond with what we know about our dataset.</p>
<p>Under the column headers <em>Studies</em> and <em>Cases</em>, the app defaults to include all studies and cases in the analysis, as indicated by the check marks (see Figure <a href="MLM-Trend.html#fig:MultiSCED-input-datasummary-Lewandowski">8.11</a>). This is appropriate for our application, because for this methods guide, we intend to illustrate the synthesis of data across all cases and studies using a three-level analysis. As an aside, the MultiSCED app allows for statistical models for a single case or two-level models of the cases nested within a single study. Thus, it provides the option to click <em>(De)select all</em> to allow researchers to only include the data from studies and cases on which they want to focus their analysis.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-input-datasummary-Lewandowski"></span>
<img src="images/MultiSCED_input.datasummary_Lewandowski2011.png" alt="Screenshot of the Data summary Section within the Input Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.11: Screenshot of the Data summary Section within the Input Page of the MultiSCED App
</p>
</div>
<p>After examining the <em>Data summary</em>, we need to specify our multilevel model. To do so, we navigate to the <em>Model</em> page (see Figure <a href="MLM-Trend.html#fig:MultiSCED-modelspec-Lewandowski">8.12</a>). There are five sections to the <em>Model</em> page: <em>Fixed effects</em> and <em>Random effects</em> on the left, and <em>One-level model</em>, <em>Two-level model</em>, and <em>Three-level model</em> on the right side of the screen. In the <em>Fixed effects</em> section, we find a list of four <em>Base variables</em> that we can include in our model. To specify a model without trends, we leave the <em>Fixed effects</em> section untouched, as the app includes <em>intercept</em> and <em>Intervention</em> by default (as noted by the checkmark next to each). Because we want to estimate a baseline slope and a change in slope that occurs with intervention, we manually check the boxes next to <em>Time</em> and <em>Intervention X Time</em>. When we check these boxes, the app automatically adds more options [i.e., <em>(Time)<sup>2</sup></em> and <em>Intervention X (Time)<sup>2</sup></em>]. However, because we anticipated linear trends and ruled out non-linear trends through visual analysis, we do not include (check) either of these additional boxes.</p>
<p>Under the <em>Random effects</em> section, the app leaves all options unchecked. Therefore, we manually select the effects necessary to match our three-level model specifications in Equations <a href="MLM-Trend.html#eq:MLM-L1-Trend">(8.1)</a> to <a href="MLM-Trend.html#eq:MLM-L3-beta3">(8.9)</a>. Allowing all regression coefficients to vary randomly across cases, we check all boxes under the <em>Case level</em> sub header. Then, we check each of the boxes under the <em>Study level</em> sub header to let the across-case study averages vary randomly for each of the coefficients across studies. As we opt to include these <em>Case level</em> and <em>Study level</em> variables, the app automatically updates our model specification on the page. In Figure <a href="MLM-Trend.html#fig:MultiSCED-modelspec-Lewandowski">8.12</a>, we present a screenshot of the resulting <em>Model</em> page, where the three-level model shown (bottom right) matches our model defined by Equations <a href="MLM-Trend.html#eq:MLM-L1-Trend">(8.1)</a> to <a href="MLM-Trend.html#eq:MLM-L3-beta3">(8.9)</a>. Under the equations, the app provides R syntax for fitting the model.</p>
<p>At this point, we have specified a very complex model and do not anticipate good estimation of the (co)variance matrices, particularly for the study-level errors. Our model includes four study-level random effects, but the data include only four unique studies. Although our process thus far (e.g., including random effects on all four terms, thereby letting all coefficients vary freely) aligns with what has typically been done in prior methodological studies focused on evaluating the appropriateness of three-level models for single-case data, much of this research uses diagonal as opposed to unstructured covariance matrices <span class="citation">(e.g., <a href="#ref-Joo_et_al_2019">Joo et al., 2019</a>; <a href="#ref-Moeyaert_Ugille_Ferron_Beretvas_VandenNoortgate_2013">Moeyaert et al., 2013</a>, <a href="#ref-Moeyaert_Ugille_Ferron_Beretvas_VanDenNoortgate_2016">2016</a>)</span>. If meta-analysts encounter estimation problems that suggest some of the variances may be 0 or correlations are at the boundaries of 1 or -1, they will need to take further action, such as simplifying the variance structure (i.e., removing error terms with little to no variability) and changing the covariance structure specification.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-modelspec-Lewandowski"></span>
<img src="images/MultiSCED_model.modelspec_Lewandowski2011.png" alt="Screenshot of the Model Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.12: Screenshot of the Model Page of the MultiSCED App
</p>
</div>
<p>After specifying the model, we use the header at the top of the website to navigate to our multilevel model results by clicking the <em>Three-level analysis</em> link. In transitioning to the <em>Three-level analysis</em> page, we may immediately note a blank page (i.e., no results) or view an error message. However, we usually encounter a small progress tracking bar in the far-right bottom of the page that conveys that estimation is in progress. It takes the MultiSCED app a few seconds to complete our model estimation and present the multilevel model results (see Figure <a href="MLM-Trend.html#fig:MultiSCED-3Level-Lewandowski">8.13</a>).</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-3Level-Lewandowski"></span>
<img src="images/MultiSCED_3level_Lewandowski2011.png" alt="Screenshot of the Three-level analysis Page of the MultiSCED App" width="60%" />
<p class="caption">
Figure 8.13: Screenshot of the Three-level analysis Page of the MultiSCED App
</p>
</div>
<p>The multilevel model estimation results indicate that if baseline continued, the estimated across-case and across-study average correct word sequences written is 8.67 per minute at the time of the first treatment observation. The immediate treatment effect estimate was an increase of 1.41 correct writing sequences (CWS) per minute (i.e., the difference between the across-case and across-study average treatment phase trajectory and projected baseline trajectory at the time of the first treatment observation). The standard error (SE) of the estimate was 1.04, indicating substantial uncertainty in the size of the average immediate treatment effect. However, this was expected given the small number of studies we used to illustrate the MultiSCED app procedures, as more studies would have resulted in a more precise estimate <span class="citation">(e.g., see <a href="#ref-datchuk2020Level">Datchuk et al., 2020</a>)</span>. The estimated across-case and across-study average baseline slope was 0.036 (<span class="math inline">\(\text{SE} = 0.078\)</span>), and estimated change in slope with intervention was 0.029 CWS per minute per intervention session (<span class="math inline">\(\text{SE} = 0.133\)</span>). Although the small, positive slope estimate in baseline and the increase in slope with intervention align with our expectations, the sampling error in both estimates is too large to conclude that either of the corresponding population parameters differ from zero.</p>
<p>We next examine the results under the <em>Random effects</em> sub header. The MultiSCED app reports the <em>Random effects</em> variance components as standard deviations (SDs). Unlike fixed effects, which have been shown to be well estimated even with the small sample sizes typical of single-case research, variance components are typically not well estimated. Rather, we expect they were estimated with considerable bias due to the limited number of studies and cases <span class="citation">(<a href="#ref-Moeyaert_Ugille_Ferron_Beretvas_VandenNoortgate_2013">Moeyaert et al., 2013</a>; <a href="#ref-Owens_Ferron_2012">Owens &amp; Ferron, 2012</a>)</span>. In addition, our examination of the data prior to modeling suggested that we likely oversimplified the model by specifying an independent and homogeneous variance structure, which leads to even more bias in the estimated variance components <span class="citation">(<a href="#ref-Joo_et_al_2019">Joo et al., 2019</a>)</span>. Consequently, although we report these parameter estimates from our model as a conceptual illustration for the purpose of this guide, we do not suggest that users of the app give serious weight to the interpretation of the <em>Random effects</em> variance components unless they have more cases and studies. Per the results reported under the <em>Random effects</em> sub header, the estimated SD of the observations around the case-specific trend lines is 1.60 (i.e., <em>Residual</em>).</p>
<p>Next, examining the between-case variability within studies (i.e., <em>Study: ID</em>), we see that the estimated SD of the case-specific intercepts is 3.55, the estimated case-specific immediate treatment effects SD is 1.08, the estimated SD of the case-specific baseline slopes is 0.063, and the estimated SD of the case-specific changes in slope with intervention is 0.15. Also note that the correlations among these random effects are plausible correlation values. In contrast, when we examine the correlation matrix for the study random effects (i.e., <em>Study</em>), we see estimated correlations at the boundaries (1 and -1) for all random effects at the study level. This signals that the covariance structure is too complex at the study level for the app to estimate correlations between our included four variables across only four studies. Thus, we will re-estimate the model while simplifying the number of study-level random effects and look to see the impact of specifying a simpler covariance structure on the estimates of the treatment effects.</p>
<p>To simplify the covariance structure for the study-level random effects, we go back to the <em>Model</em> page and deselect some of the <em>Random effects</em> options listed under the <em>Study level subheading</em>. As shown in Figure <a href="MLM-Trend.html#fig:MultiSCED-modelspec-simpler-Lewandowski">8.14</a>, we uncheck <em>Time</em>, <em>Intervention</em>, and <em>Intervention X Time</em>. Although conceptually any of these coefficients could vary from one study to the next, we only have four studies in our example, which is not sufficient to estimate so many variance components.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-modelspec-simpler-Lewandowski"></span>
<img src="images/MultiSCED_model.modelspec_simpler_Lewandowski2011.png" alt="Screenshot of the Re-Specified Model with Fewer Study-Level Random Effects (Model Page)" width="60%" />
<p class="caption">
Figure 8.14: Screenshot of the Re-Specified Model with Fewer Study-Level Random Effects (Model Page)
</p>
</div>
<p>We show the results from this simpler re-specified model in Figure <a href="MLM-Trend.html#fig:MultiSCED-3Level-simpler-Lewandowski">8.15</a>. With this model, the across-case and across-study average immediate effect is 1.03 (<span class="math inline">\(\text{SE} = 0.64\)</span>) and the estimated effect of the intervention on the slope is -0.03 (<span class="math inline">\(\text{SE} = 0.06\)</span>). The point estimates for the effects have changed, but the conclusion of a potential non-effect (i.e., the population effect parameters may be zero) remains the same. Although we eliminated the correlations of 1 and -1 in the study-level random effect estimates, the estimated variance for the study-level intercepts is 0, suggesting insufficient between-study variability necessary to obtain a non-zero estimate.</p>
<div class="figure"><span style="display:block;" id="fig:MultiSCED-3Level-simpler-Lewandowski"></span>
<img src="images/MultiSCED_3level_simpler_Lewandowski2011.png" alt="Screenshot of the Three-level analysis Page for the Re-Specified Model with Fewer Study Level Random Effects" width="60%" />
<p class="caption">
Figure 8.15: Screenshot of the Three-level analysis Page for the Re-Specified Model with Fewer Study Level Random Effects
</p>
</div>
<p>After comparing both models, we consider the degree to which we may obtain better treatment effect estimates from one model or another. For example, could we achieve better estimates if using a model that allows all effects to vary randomly across cases and studies, or a model with a covariance structure that is easier to estimate? Similarly, is it better to model heterogeneity in the error variance between cases and phases, and is it best to model autocorrelation among the case-level errors? Researchers have shown that the misspecification of the covariance structure as either too simple or too complex at any of the three levels introduces little to no bias in the average treatment effect estimates, leading to relatively accurate inferences about the average treatment effect <span class="citation">(<a href="#ref-baek_Ferron_2020">E. Baek &amp; Ferron, 2020</a>; <a href="#ref-Joo_Ferron_2019">Joo &amp; Ferron, 2019</a>; <a href="#ref-Moeyaert_Ugille_Ferron_Beretvas_VandenNoortgate_2013">Moeyaert et al., 2013</a>, <a href="#ref-Moeyaert_Ugille_Ferron_Beretvas_VanDenNoortgate_2016">2016</a>; <a href="#ref-Petit-Bois_2014">Petit-Bois, 2014</a>; <a href="#ref-Petit-Bois_Baek_VandenNoortgate_Beretvas_Ferron_2016">Petit-Bois et al., 2016</a>)</span>. However, this research examines a limited range of conditions. We hope that future research will serve to further clarify the optimal approach for estimating three-level LMMs for SCD study data. In addition, SCD studies will sometimes have outcomes that present more severe violations of the normality and homogeneity assumptions than we encountered here. Useful directions for future research include: (a) determining at what point the violations are severe enough and sample sizes large enough to prefer the use of GLMMs, (b) providing further guidance on the most appropriate ways to specify and estimate GLMMs <span class="citation">(<a href="#ref-Li_Luo_Baek_Thompson_Lam_2023">Li et al., 2023</a>)</span>, and (c) producing easy-to-use software to make GLMMs more readily accessible to SCD researchers.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-baek2016using" class="csl-entry">
Baek, E. K., Petit-Bois, M., Van den Noortgate, W., Beretvas, S. N., &amp; Ferron, J. M. (2016). Using visual analysis to evaluate and refine multilevel models of single-case studies. <em>The Journal of Special Education</em>, <em>50</em>(1), 18–26.
</div>
<div id="ref-baek_Ferron_2020" class="csl-entry">
Baek, E., &amp; Ferron, J. J. M. (2020). Modeling heterogeneity of the level-1 error covariance matrix in multilevel models for single-case data. <em>Methodology</em>, <em>16</em>(2), 166–185. <a href="https://doi.org/10.5964/meth.2817">https://doi.org/10.5964/meth.2817</a>
</div>
<div id="ref-datchuk2020Level" class="csl-entry">
Datchuk, S. M., Wagner, K., &amp; Hier, B. O. (2020). Level and <span>Trend</span> of <span>Writing Sequences</span>: <span>A Review</span> and <span>Meta-Analysis</span> of <span>Writing Interventions</span> for <span>Students With Disabilities</span>. <em>Exceptional Children</em>, <em>86</em>(2), 174–192. <a href="https://doi.org/10.1177/0014402919873311">https://doi.org/10.1177/0014402919873311</a>
</div>
<div id="ref-Declercq2020" class="csl-entry">
Declercq, L., Cools, W., Beretvas, S. N., Moeyaert, M., Ferron, J. M., &amp; Van den Noortgate, W. (2020). MultiSCED: A tool for (meta-)analyzing single-case experimental data with multilevel modeling. <em>Behavior Research Methods</em>, <em>52</em>(1), 177–192. <a href="https://doi.org/10.3758/s13428-019-01216-2">https://doi.org/10.3758/s13428-019-01216-2</a>
</div>
<div id="ref-Declercq2019" class="csl-entry">
Declercq, L., Jamshidi, L., Fernández-Castilla, B., Beretvas, S. N., Moeyaert, M., Ferron, J. M., &amp; Van den Noortgate, W. (2019). Analysis of single-case experimental count data using the linear mixed effects model: A simulation study. <em>Behavior Research Methods</em>, <em>51</em>(6), 2477–2497. <a href="https://doi.org/10.3758/s13428-018-1091-y">https://doi.org/10.3758/s13428-018-1091-y</a>
</div>
<div id="ref-Joo_Ferron_2019" class="csl-entry">
Joo, S.-H., &amp; Ferron, J. M. (2019). Application of the within- and between-series estimators to non-normal multiple-baseline data: Maximum likelihood and bayesian approaches. <em>Multivariate Behavioral Research</em>, <em>54</em>(5), 666–689. <a href="https://doi.org/10.1080/00273171.2018.1564877">https://doi.org/10.1080/00273171.2018.1564877</a>
</div>
<div id="ref-Joo_et_al_2019" class="csl-entry">
Joo, S.-H., Ferron, J. M., Moeyaert, M., Beretvas, S. N., &amp; Van den Noortgate, W. (2019). Approaches for specifying the level-1 error structure when synthesizing single-case data. <em>The Journal of Experimental Education</em>, <em>87</em>(1), 55–74. <a href="https://doi.org/10.1080/00220973.2017.1409181">https://doi.org/10.1080/00220973.2017.1409181</a>
</div>
<div id="ref-lewandowski2011effects" class="csl-entry">
Lewandowski, S. C. (2011). <em>The effects of a modified version of self-regulated strategy development and self-talk internalization strategy on writing and self-talk for elementary students with attentional difficulties</em> [PhD thesis]. <a href="https://d.lib.msu.edu/etd/28">https://d.lib.msu.edu/etd/28</a>
</div>
<div id="ref-Li_Luo_Baek_Thompson_Lam_2023" class="csl-entry">
Li, H., Luo, W., Baek, E., Thompson, C. G., &amp; Lam, K. H. (2023). Multilevel modeling in single-case studies with count and proportion data: A demonstration and evaluation. <em>Psychological Methods</em>, No Pagination Specified–No Pagination Specified. <a href="https://doi.org/10.1037/met0000607">https://doi.org/10.1037/met0000607</a>
</div>
<div id="ref-Moeyaert_Ugille_Ferron_Beretvas_VandenNoortgate_2013" class="csl-entry">
Moeyaert, M., Ugille, M., Ferron, J. M., Beretvas, S. N., &amp; Van den Noortgate, W. (2013). The three-level synthesis of standardized single-subject experimental data: A monte carlo simulation study. <em>Multivariate Behavioral Research</em>, <em>48</em>(5), 719–748. <a href="https://doi.org/10.1080/00273171.2013.816621">https://doi.org/10.1080/00273171.2013.816621</a>
</div>
<div id="ref-Moeyaert_Ugille_Ferron_Beretvas_VanDenNoortgate_2016" class="csl-entry">
Moeyaert, M., Ugille, M., Ferron, J. M., Beretvas, S. N., &amp; Van Den Noortgate, W. (2016). The misspecification of the covariance structures in multilevel models for single-case data: A monte carlo simulation study. <em>The Journal of Experimental Education</em>, <em>84</em>(3), 473–509. <a href="https://doi.org/10.1080/00220973.2015.1065216">https://doi.org/10.1080/00220973.2015.1065216</a>
</div>
<div id="ref-Owens_Ferron_2012" class="csl-entry">
Owens, C. M., &amp; Ferron, J. M. (2012). Synthesizing single-case studies: A monte carlo examination of a three-level meta-analytic model. <em>Behavior Research Methods</em>, <em>44</em>(3), 795–805. <a href="https://doi.org/10.3758/s13428-011-0180-y">https://doi.org/10.3758/s13428-011-0180-y</a>
</div>
<div id="ref-Petit-Bois_2014" class="csl-entry">
Petit-Bois, M. (2014). <em>A monte carlo study: The consequences of the misspecification of the level-1 error structure</em> [PhD thesis]. <a href="https://scholarcommons.usf.edu/etd/5341">https://scholarcommons.usf.edu/etd/5341</a>
</div>
<div id="ref-Petit-Bois_Baek_VandenNoortgate_Beretvas_Ferron_2016" class="csl-entry">
Petit-Bois, M., Baek, E. K., Van den Noortgate, W., Beretvas, S. N., &amp; Ferron, J. M. (2016). The consequences of modeling autocorrelation when synthesizing single-case studies using a three-level model. <em>Behavior Research Methods</em>, <em>48</em>(2), 803–812. <a href="https://doi.org/10.3758/s13428-015-0612-1">https://doi.org/10.3758/s13428-015-0612-1</a>
</div>
<div id="ref-stotz2008Effects" class="csl-entry">
Stotz, K. E., Itoi, M., Konrad, M., &amp; Alber-Morgan, S. R. (2008). Effects of <span class="nocase">Self-graphing</span> on <span>Written Expression</span> of <span>Fourth Grade Students</span> with <span>High-Incidence Disabilities</span>. <em>Journal of Behavioral Education</em>, <em>17</em>(2), 172–186. <a href="https://doi.org/10.1007/s10864-007-9055-9">https://doi.org/10.1007/s10864-007-9055-9</a>
</div>
<div id="ref-walker2007improving" class="csl-entry">
Walker, B. D., Shippen, M. E., Houchins, D. E., &amp; Cihak, D. F. (2007). Improving the writing skills of high school students with learning disabilities using the <span>Expressive Writing</span> program. <em>International Journal of Special Education</em>, <em>22</em>(2), 66–76.
</div>
<div id="ref-walker2005using" class="csl-entry">
Walker, B., Shippen, M. E., Alberto, P., Houchins, D. E., &amp; Cihak, D. F. (2005). Using the expressive writing program to improve the writing skills of high school students with learning disabilities. <em>Learning Disabilities Research &amp; Practice</em>, <em>20</em>(3), 175–183. <a href="https://doi.org/10.1111/j.1540-5826.2005.00131.x">https://doi.org/10.1111/j.1540-5826.2005.00131.x</a>
</div>
<div id="ref-WWC2022" class="csl-entry">
What Works Clearinghouse. (2020a). <em>What <span class="nocase">Works Clearinghouse Procedures and Standards Handbook</span></em> (Version 5.0). <span>U.S. Department of Education, Institute of Education Sciences, National Center for Education Evaluation and Regional Assistance.</span>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="MLM-NoTrend.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intro-case-specific-es.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["SCD-Methods-Guide.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
